\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{amsmath}
\usepackage{bm}
\usepackage[authoryear,round]{natbib}
\bibliographystyle{plainnat}
\DefineVerbatimEnvironment{Sinput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontshape=sl,
  fontfamily=courier,fontseries=b, fontsize=\scriptsize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontfamily=courier,fontseries=b,%
  fontsize=\scriptsize}
%%\VignetteIndexEntry{eatRep: a package to analyze multiple imputed data in complex survey designs}
%%\VignetteDepends{eatRep}
%%
\newcommand{\trans}{\ensuremath{^\mathsf{T}}}
\newcommand{\invtrans}{\ensuremath{^\mathsf{-T}}}
\title{eatRep: a package to analyze multiple imputed data in complex survey designs}
\author{Sebastian Weirich\\Humboldt University Berlin, Germany}
\begin{document}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,strip.white=true,keep.source=TRUE}
\SweaveOpts{include=FALSE}
\setkeys{Gin}{width=\textwidth}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\package}[1]{\textsf{\small{#1}}}
\maketitle
\begin{abstract}
  Estimation of simple descriptive statistics becomes cumbersome, if the sample cannot be considered to be a 
  (completely) random draw from the population for which descriptives should be interpreted. This occurs in 
  weighted samples or clustered samples. The same is true if the variables of interest stem from a multiple 
  imputation process and occur, for example, as plausible values. In the estimation of standard error, we 
  then have to account for two possible sources of uncertainty: first the uncertainty due to a clustered 
  sample, and second the uncertainty due to multiple imputed data. This tutorial describes some basic 
  analyses to compute descriptives in complex survey designs using the R package \code{eatRep}, which 
  was designed mainly to supply replications methods in R. Such methods are appropriate to analyze both 
  clustered and multiple imputed data as well. To date, the Jackknife-1 (JK1), Jackknife-2 (JK2) and the 
  balanced repeated replicates (BRR) methods are supported. Some functions overlap with methods provided 
  in the computer software WesVar \citep{Westat2000}---in this case the package only allows for executing
  these analyses in R, which may be easier to implement due to a syntax related interface. Some methods 
  in WesVar are not completely implemented in \code{eatRep} yet, for example bootstrapping methods. For 
  bootstrapping, alternative \code{R} packages (e.g. \code{boot}) may be used. However, some methods are 
  only implemented in \code{eatRep}, for example analyses for nested imputed data, linear logistic 
  regression models, or trend analyses. Examples considering the latter one are not yet included 
  in this vignette. The examples 6 to 6d from the help page of the \code{defineModel} function in 
  the \code{eatModel} package contain some exhaustive demonstrations of trend analyses.\\ 
  
  \code{eatRep} heavily relies on the \code{survey} package \citep{Lumley2012} which functions has been extended by methods 
  for multiple imputed data. While the functional principle of \code{survey} is based on replication of conventional 
  analyses, \code{eatRep} is based on replication of \code{survey} analyses to take multiple imputed data into account.
  %%  The following tutorial does not intend to give theoretical foundations nor a critical review of those methods or of anything else. Also, this is 
%%  not an introduction to R.
\end{abstract}

<<preliminaries,echo=FALSE,print=FALSE>>=
library(eatRep)
@

\section{Introduction}
\label{sec:intro}

In a completely random sample, the mean
\begin{equation}
  \label{eq:1}
  %% \bar x= \frac{\sum\limits_{i=1}^n(x_i)}{n}
  \bar x= n^{-1}\sum\limits_{i=1}^n(x_i)
\end{equation}
is an unbiased estimate for the corresponding mean
\begin{equation}
  \label{eq:2}
  %% \mu= \frac{\sum\limits_{i=1}^N(x_i)}{N}
  \mu= N^{-1}\sum\limits_{i=1}^N(x_i)
\end{equation}
of the underlying population the sample was drawn from. This does not hold for dispersion measures (variance and standard
deviation), as the variance in a sample is always less than the variance in the population the sample was drawn from. The transformation,
however, is very easy made: The variance in a sample is multiplied by $n/(n-1)$ to obtain population variance, where $n$ is the sample size.
Based on
\begin{equation}
  \label{eq:3}
  %% \sigma^2= \frac{\sum\limits_{i=1}^N(x_i-\mu)^2}{N}
  \sigma^2= N^{-1}\sum\limits_{i=1}^N(x_i-\mu)^2
\end{equation}
for the population with $N$ elements, we apply
\begin{equation}
  \label{eq:4}
  %% s^2= \frac{\sum\limits_{i=1}^n(x_i-\bar x)^2}{n-1}
  s^2= (n-1)^{-1}\sum\limits_{i=1}^n(x_i-\bar x)^2
\end{equation}
to estimate population variance from a sample of size $n$. In a weighted sample, i.e. if the population weights differ between
examinees in the sample, mean and variance may be estimated by incorporating these population weights.
(In a completely random sample, these weights equal 1 for each examinee.)
\begin{equation}
  \label{eq:5}
  \bar x_w= \sum\limits_{i=1}^n\left(\dfrac{w_i}{W}x_i\right) ,
\end{equation}
\begin{equation}
  \label{eq:6}
   s_{w}^{2}= \sum\limits_{i=1}^n \dfrac{w_i}{W-1}(x_i-\bar x)^2 ,
\end{equation}
%%\begin{equation}
%%  \begin{aligned}
%%  \label{eq:5}
%%  \bar x_w&= \dfrac{\sum\limits_{i=1}^n\left(\dfrac{w_n}{W}x_i\right)}{W}\\
%%  s^2&= \dfrac{\sum\limits_{i=1}^n \dfrac{w_n}{W-1}(x_i-\bar x)^2}{n} \\
%%  s^2&= n^{-1}\sum\limits_{i=1}^n \frac{w_n}{W-1}(x_i-\bar x)^2 ,
%%  \end{aligned}
%%\end{equation}
where $w_i$ is the case weight of the \emph{i}th person, and $W$ is the sum over all case weights, i.e. $W=\sum w_i$.
To summary, the crucial point in the estimation of population variance estimates is the factor $n/(n-1)$. Unfortunately, this factor only
applies when we sample (conditionally) independently from the population, as in completely random samples or weighted
random samples. In a clustered sample, however, where schools or classes are sampling units instead of single persons,
the relationship between sample and population variance is not so clear at all. The reason is that persons \emph{within} a cluster (for
example pupils in a class) often share a common variance. The sample variance underestimates the population variance, but more
severely than indicated by the factor $n/(n-1)$. To estimate the relationship between sample and population variance, it is
necessary to estimate the variance explained by the cluster.\\

Without taking the cluster structure into account, we would not only obtain biased variance estimates but biased 
standard errors, too \citep{luke2009}. This problem occurs in the same way for estimation of frequency tables, 
quantiles or estimates of (linear) regression models. To gain unbiased estimates, several replication methods 
were introduced, which based on the same principle: To estimate the proportion by which the variance in the 
sample is underestimated due to a clustered structure \citep{Lumley2004}. In the Jackknife-2 (JK2) procedure 
this is implemented by reproducing the original sample to several replicates. In each replicate one clustering 
unit (e.g. one class) of only one primary sampling unit (PSU) is replaced by another class, which therefore 
occurs two times in the sample. Each replicate is analyzed if it would have been a completely random sample. 
Recognize what is to be expected then: If the variance is explained partially by the clusters, removing
one sampling unit should decrease the variance of the sample slighty. Conversely, the point estimates of each 
replication sample should vary slightly. The variance in the point estimates between the replicates is used to 
estimate the corresponding standard errors. Otherwise, if there is no variance between clusters, removing one 
cluster would have no effect on the variance estimate, and the point estimates between replicates would have 
no or only very little variance. In this case replication methods will result in exactly the same variance 
estimates and standard errors as they would follow from conventional analysis. The balanced repeated replicates 
(BRR) method is quite similar. The original sample is reproduced to several replicates. In each replicate 
one clustering unit (e.g. one class) \emph{of each PSU} is replaced by another class, which therefore 
occurs two times in the sample. Each replicate then is analyzed if it would have been a completely random sample.
For further details, see Rust and Rao (1996).\\

For the purpose of illustration, assume a simple population mean which has to be estimated from a completely random 
sample of $N=1000$. To estimate the standard error of this mean, we may apply a rather laborious method: to draw 100 
samples (with replacement) from our original sample, each of $N=1000$, and compute the mean in each sample. The standard 
deviation of the 100 mean estimates is the standard error of the mean. Of course, this bootstrap method is far to 
cumbersome, as in a random sample the standard error can be estimated in a much more easier way. However, in a 
clustered sample, an extension of this bootstrap method is appropriate indeed.
Several software \citep{Westat2000} and free R packages such as \code{survey} \citep{Lumley2012}
do allow for several replication methods.\\

The situation is becoming still more complicated when the variables in the data to be analysed occur as (multiple) 
imputed data, for example as plausible values. Where missing values may cause biased parameters, analyses are conducted with 
imputed data. Often, the original data which includes missing values is reproduced several times, whereas the missing entries 
are filled with a set of plausible values, which results in several imputed data sets. 
To gain unbiased parameter estimates, the analyses are conducted for each data set 
separately and pooled afterwards according to \citet{Rubin1987}.\\

If we have both, a clustered sample with multiple imputed data, both methods have to be combined. This leads to a replication
of replications. Analyses have to be repeated to account for the clustered structure, and the results of these replications 
have to be repeated to account for multiple imputed data. In the following, we refer to ``cluster replicates'' 
and ``imputation replicates'' to differentiate between both.

\section{Estimate some population descriptives}
\label{sec:ex1}
In this example, we use some artificial data from the context of educational research. We may think of a stratified clustered 
sample of German fourth-grade primary school students whose reading competencies are measured. Proficiency estimates 
obtained from a Item response Theory (IRT) marginal model are included as plausible values. Each plausible value may be 
recognized as an imputation of the latent competence construct. The data are represented in the long format.\\ 

<<reading_writingdef>>=
library(eatRep)
data(reading)
str(reading)
@

Requesting the data structure provides us with information about the number and type of variables and the number of
examinees. \code{"idstud"} is a person identifier for 4,619 distinct examinees, \code{"wgtSTUD"} a person weight, 
\code{"sex"} denotes each person's sex, \code{"country"} denotes the country the person comes from. \code{"JKZone"} 
and \code{"JKrep"} denote jackknifing variables which contains information about which unit has to be replaced by 
which other unit in which replicate of the original data. \code{"income"} is each person's financial income. The next
two variables, \code{"nest"} and \code{"imputation"} describe the multiple imputed structure of the data. The data 
stem from a nested multiple imputation model with 2 nests and 3 imputations in each nest. The princiles of nested
imputations will be elucidated later; for the moment, we may content ourself with data from the first nest only, 
i.e. we split the data and only cosider cases for which $nest=1$. We may think of \code{"score"} as the the 
plausible value estimate for the reading competence. Hence, if $nest=1$ and $imputation=3$, the value in the 
\code{"score"} columns refers to the third plausible value in the first nest for the reading competence. 
Please note that the three imputations of the reading competence occur as one variable in the data set. 
Hence, each individual is represented in several rows. This is quite usual if multiple imputed data is 
presented in a long format dataset. \code{eatRep} strictly requires the long format. To transform wide-format
data frame into long-format data frames (and vice versa), use the \code{reshape2} package. Please note further 
that the dataset does not contain any replicates, only the information required for generating them, captured 
in the \code{"JKZone"} and \code{"JKrep"} variables. 

\subsection{Populations means, standard deviations, variances and mean differences}
\label{subsec:means}

We now want to compute the means by each country, considering the clustered structure as well as the multiple 
imputed data structure. The replicates do not need to be created separately, as they will be generated in each 
analysis automatically. Even in large data sets this takes only a few seconds. First we create a subset which 
only contains data from the first nest. The analysis then is conducted with this subset.\\

<<readingMeansByCountrydef>>=
readN1<- subset(reading, nest == 1 ) 
means <- jk2.mean(datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", groups = "country", 
         dependent = "score")
@

When applying the jackknife method, the primary sampling unit (PSU) often is the jackknife zone (JKZone),
and the replication indicator often is the jackknife replicate indicator (JKrep). While the function is operating, 
some additional information is displayed on console. First we see that one analysis is run according to 
\code{'group.splits = 1'}. We will subsequently exemplify this enigmatic message. Further, we see that \code{jk2.mean}
assumes an ``unnested'', i.e. a structure with three imputations. This refers to what we've called 
``imputation replicates''. The output then speaks about 81 replicate weights which are created due to 81 distinct 
jackknifing zones in the JKZone variable. This information refers to the ``cluster replicates'' and implies that 
the subsequent analysis has to be repeated 81 times \emph{for each imputation}. Overall, $3\times 81=243$ analyses are 
run overall.\\ 

In each of the 81 replication samples, one unit (e.g. school) of a certain jackknifing zone is missing and the weights 
of the other unit of the same zone are doubled. The data in all other zones remain unchanged. The analyses are repeated 
81 times, \emph{using the same plausible value} as the dependent variable. Only the weights vary between the 
``cluster replicates'': each of the 81 replicates once a time is used as the weighting variable. Each of the 81 
analysis revealed slighty different results. This variation is used to estimate the sampling variance which then is used 
to compute the standard error, which is pooled across 81 ``cluster replicates''. When finished, the analysis 
approaches the second ``imputation replicate'' and switches to the second plausible value which now is used as the 
dependent variable in 81 analyses due to the 81 ``cluster replicates''. After all, three pooled estimates and three 
pooled standard errors resulted which differ slightly in each ``imputation replicate''. The three estimates and 
standard errors are pooled according to \citet{Rubin1987}. To sum up, the pooled results are pooled again to account for 
both: multiple imputed data in a clustered sample.\\

The little dots continuously appearing on the console therefore refer to ``imputation replicates'' and are intended 
to work as a rough progress bar. Each dot represents one ``imputation replication''. When the procedure finished, 
the results are pooled in the case of more than one imputation.\\

<<readingMeansByCountryResultsdef>>=
means[c(1:4,19:20),]
@

The output is a data frame in the long format with 30 rows and at least six columns. To keep the 
overview, only a few selected rows are displayed here. For each subpopulation denoted by the 
\code{groups} statement (here: \code{LandA}, \code{LandB} and \code{LandC}), each dependent 
variable (here: only the reading competence), each parameter (we requested mean, variance, 
standard deviation and sample size or population size) and each coefficient (i.e., the 
estimate and the corresponding standard error) the corresponding value is given. However, 
the output more suited for further processing than for clear arragement, as the 
values are displayed in the long format as well as in exponential notation, for example. 
To display the results in the more common wide format, use the \code{reshape2} package. 
Alternatively, an abbreviated display of the results is provided by the \code{dM} 
function (whereas dM stands for ``display means''). You may think of \code{dM} as 
a simple summary function which is not intended for saving results or further processing
as the results are displayed in an abbreviated (i.e., rounded) manner to offer clear 
arrangement on console. The \code{dM} function has an additional argument to omit 
displaying parameters or coefficients you are not interested at the moment. \\

<<readingMeansByCountryResultsdefSummary>>=
dM(means, omitTerms = c("var", "Ncases","NcasesValid", "meanGroupDiff") )
@

Can we see see how the results would change if we do not consider the clustered 
structure? Yes, we can. We simply leave out the jackknifing arguments \code{JKZone} 
and \code{JKrep}. The type argument then is automatically ignored likewise, whether 
specified or not. The results will be pooled only due to multiple imputed data:\\

<<readingMeansByCountry2def>>=
means <- jk2.mean(datL = readN1, ID = "idstud", wgt = "wgtSTUD", 
         imp = "imputation", groups = "country", dependent = "score")
dM(means, omitTerms = c("var", "Ncases","NcasesValid", "meanGroupDiff") )
@

We see that the means are completely unaffected, but the standard deviation now is lower. Consequently, also 
the standard errors for the mean estimates are considerably lower. (Standard errors for standard deviations and for 
variances are not implemented yet.) If we decide to leave out the weights as well, we would additionally expect to receive 
different means now:\\

<<readingMeansByCountry3def>>=
means <- jk2.mean(datL = readN1, ID = "idstud", 
         imp = "imputation", groups = "country", dependent = "score")
dM(means, omitTerms = c("var", "Ncases","NcasesValid", "meanGroupDiff") )
@

If we additionally decide to ignore the imputations and treat, for example, the first plausible value as it would have been 
a fully observed measure of the latent competency, the function call would be the following:\\

<<readingMeansByCountry4def>>=
means <- jk2.mean(datL = subset(readN1,imputation==1),  ID = "idstud", 
         imp = "imputation", groups = "country", dependent = "score")
dM(means, omitTerms = c("var", "Ncases","NcasesValid", "meanGroupDiff") )
@

The estimation of standard errors now no longer accounts for the uncertainty due to imputation. Furthermore, also the 
mean estimates have changed as the estimation now is based only on the first plausible value. \\

Two possible interesting features should be emphasized in the following. First assume that we do not have one, but two
grouping variables, namely \code{country} and \code{sex}. As we have three countries and two sex values, 
the whole population is splitted into $3\times 2=6$ subpopulations for which descriptives can be requested. If we 
additionally are interested in the descriptives of the whole population or the descriptives 
\emph{within each country, but together for both sex groups}, we can use the \code{group.splits} argument to 
particularly specify the groups we are interested in. Let us consider for example the two grouping variables 
\code{country} and \code{sex}. If \code{group.splits} equals 2 (the default, i.e., the number of grouping 
variables), descriptives for the $3\times 2=6$ subpopulations are computed. If \code{group.splits} 
is \code{1:2}, descriptives for each country (e.g., across sex) and each sex group (e.g. across countries) 
additionally are computed. If \code{group.splits} is \code{0:2}, descriptives also for the whole population 
(e.g. across sex \emph{and} countries) are computed. \\

The second feature is about mean differences. Suppose you are interested in sex differences \emph{within} each 
country. The grouping variable for which mean differences should be computed has to be specified in 
the \code{group.differences.by} argument. For a grouping variable with $K$ levels, all $K!/(2!\times(K-2)!)$ comparisons
are computed. It is important that the group defined in \code{group.differences.by} also has to occur in the \code{groups} 
statement, otherwise \code{group.differences.by} will be ignored. To estimate sex differences \emph{within each 
country}, sex and country have to be part of the \code{groups} statement, whereas only sex has to be
used in the \code{group.differences.by} argument. Both features are illustrated in the following example:\\

<<readingMeansByCountry4def>>=
means <- jk2.mean(datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", groups = c("sex","country"), 
         group.splits = c(0,2), group.differences.by = "sex", dependent = "score")
@

First note the \code{group.splits} is set to \code{c(0,2)}, which means that we request descriptives for the whole 
population and the 6 subpopulations. Consequently, two analyses are conducted. The \code{group.differences.by} only
applies for the second analysis, as the gender group is not considered relating to the whole population analysis. 
To estimate sex differences \emph{across all countries}, only sex has to be part of the \code{group} statement, 
and only sex has to be used in the \code{group.differences.by} argument. The output of the analysis is nearly the 
same as we would have omitted the \code{group.differences.by} argument, but now, some additional lines have joined. 
Again, we may use the \code{dM} function to display the part of the results we are interested in---note that now we 
do \emph{not} exclude \code{meanGroupDiff} from the results to summarize:\\

<<readingMeansByCountry5def>>=
dM(means, omitTerms = c("var","Ncases", "NcasesValid"))
@

The output now changed slightly: additionally to several group columns, one column for group membership is provided. 
The last line labelled \code{wholeGroup} provides results concerning the whole population. The line labelled 
\code{male\_LandC} contains values for the males in LandC. Moreover, three mean differences were computed. In each
federal state, the difference between males and females is given. \\

\subsection{Frequency tables}
\label{subsec:freqs}

Computation of frequency tables works in the same manner as in the examples mentioned before. 
Representative for several possible analyses only one example is given below. Consider the 
\code{score} column we used as the dependent variable in all previous analyses. Suppose we
define a cut score criterion, i.e. all persons with at least 500 points passed, the other 
ones failed. We now may be interested whether the percentage of pass/fails differs between 
countries. We henceforward consider the column \code{passed} as dependent variable which is 
a simple indicator, i.e. a categorical variable with two categories (computation of frequency 
tables for variables with more than two categories are possible, too). Categorical variables 
are often represented as factors in R, which is quite straightforward. However, the 
\code{"passed"} variable is of class numeric. This is an inconsistency which may cause annoying 
misinterpretations when such variables are called in functions related to the generalized linear 
model like \code{aov()}, \code{glm()} etc. For the computations of frequency tables it is not 
necessary to convert the variable class to factor.\\ 

We now are interested in the relative frequencies of this groups in the different countries 
and within each country for different groups of gender. As before, we want to take the cluster 
structure and multiple imputations into account. Moreover, we are interested whether the distribution 
of pass/fail is different for males vs. females within specific countries. This is done via a chi 
square test. The test statistic is pooled according to the clustered structure and the imputations. 
To call for the chi square test, we can use the \code{group.differences.by} argument:\\

<<hiseiFreqsByCountryGenderdef>>=
freqs <- jk2.table( datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", groups = c("country", "sex"), 
	       group.differences.by = "sex", dependent = "passed")
dT(freqs, percent = TRUE)
@

The output is a single data frame in the long format. To make the output more pleasing to the 
eye, a short summary function \code{dT} is just waiting to do her job, to summarize the results.
The first column refers to the groups specified in the analysis (in our example: 
\code{country} and \code{sex}). The next column gives the name of the dependent variable 
(i.e. ``passed''). The ``labels'' of the dependent variable now are captured in the 
column names of the summary table. We see that in country \code{"LandA"} 35.8 percent of the 
females and 47.8 percent of the males \emph{do not pass}. As in the examples mentioned 
before, these analyses may be conducted without considering clustered structure. See whether 
the standard errors will change.\\ 

The output of the summary function \code{dT} does not contain results of the chi square test.
So far, we have to extract the results by ourself:\\

<<hiseiFreqsExtraction>>=
options(scipen=4)
freqs[which(freqs[,"parameter"] == "chiSquareTest"),]
@

In each of the three countries a chi square test was conducted separately. For \code{LandA}, 
the \emph{p} is <.001, hence the distribution of passed/failed significantly differs between 
males and females in \code{LandA}. However, \code{LandB} and \code{LandC} reveals another 
picture---there are no sex differences in the rate of pass/fail. As we have imputed data, 
we additionallz have an chi square approximation. See the help page of \code{micombine.chisquare}
of the \code{miceadds} package for further details. \\

Let's devote little attention to the problem of missing values. In the example mentioned above, 
it does not seem plausible to assume missing values on the \code{"passed"} variable. Without
available data for an examinee, the case will be excluded from the data previously. But consider 
a questionnaire where pupils are asked about there parents' profession, for example to compute 
the family's highest socio-economical income (HISEI). Some examinees might have choosen the 
option ``I don't know my parents' profession''. Conceptually, it makes considerably more 
sense to define a separate category during the data preparation, for example ``lowest HISEI'', 
``medium HISEI'', ``highest HISEI'', ``unknown HISEI''. Families without valid
HISEI information then will be considered as a separate group in the analyses. Applying 
\code{jk2.table} then will give frequencies for four groups. However, if the ``Dont't know'' 
cases appear as ``NA'' values, it is possible to define them as a distinct category for which 
relative frequencies can be computed. Only for illustration, let us generate some missing values 
in some of the imputations and repeat the analysis subsequently. You will see that a new category 
has joined to the output, which is labelled \code{"<NA>"}. \\

<<redefineValues2def>>=
readN1[,"passedNA"] <- readN1[,"passed"]
readN1[ sample(nrow(readN1), 100, FALSE) ,"passedNA"]   <- NA
freqs2<- jk2.table( datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", groups = c("country", "sex"), 
	       dependent = "passedNA", separate.missing.indicator = TRUE)
dT(freqs2)
@	  

\subsection{Quantiles}
\label{subsec:quantiles}

Estimation of quantiles for numerical variables is possible using the function 
\code{jk2.quantile}. All related analyses mentioned up to this point apply in the 
same way. Note that these analyses apply for numerical dependent variables. 
See the examples in the help file of \code{jk2.quantile()}.\\

\section{Generalized linear models}
\label{sec:ex2}

Considering multiple imputations and clustered structure in the estimation of generalized 
linear models is based on the same principles as aforementioned. However, some additional 
comments due to specific characteristics of regression models have to be made. First we 
now have another type of variable---independent variables, which may occur as multiple 
imputed variables, too. Second, we have to specify the regression expression, as in 
\code{glm()}, for example. Third, we will have to specify the kind of regression we 
propose to estimate, for example linear or logistic regression. We start with a simple 
example using the same data as before.\\

<<regression1def>>=
mod1  <- jk2.glm(datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", groups = "country",
         formula = score~sex*income, family=gaussian(link="identity") )
@

As we might have expected, the outcome is a single data frame in the long format. 
And long really means long! For our purpose, it may be sufficient to content ourself 
with the summary provided by \code{dG}. But beforehand let us consider how many regression 
analyses are conducted and how many results we expect to find. The message on the console 
speaks of about ``1 analysis overall'' according to two \code{group.splits = 1}. 
But strictly speaking, we have estimated three regression analyses, as the model is 
fitted in each group separately. As we specified one group variable dividing the data into 
three distinct groups, for which we instruct \code{jk2.glm()} to fit the regression model 
separately, we find results of the three models in the results. More specifically, for each 
country, an intercept and two regression coefficients according to \code{gender} and 
\code{INCOME} are estimated. The \code{dG} function allows us to have a look only at a specific 
result out of the 3 analyses. \code{analyses = 1:2} advises the function to display the results 
of the first and second analysis. First we should consider that each single analyses is characterized 
by two variables, the group for which the model is fitted, and the dependent variable. In the heading 
we find information about both. The actual regression results are displayed underneath. \\

<<regression1defResults1>>=
res   <- dG(mod1, analyses = 1:2)
@

Remember what was said about factors in the chapter about frequency tables: The gender variable 
now has to be defined explicitly to be of class factor! Otherwise, albeit gender variable may be 
coded as 0/1, it would be treated to be a continuous numeric variable. With only two levels---male 
and female---this may have no effect on the results, but consider a factor variable with three 
levels, which may be coded 0, 1 and 2. We are interested in two coefficients which correspond to 
the effect of level 1 vs. level 0 and the effect of level 2 vs. level 0. If we refrain from defining 
the variable to be of class factor, only one coefficient is computed, and the variable is assumed to 
be continuous. What we see additionally is that R implicitly defined the female group to be the 
reference---the regression parameter was labelled \code{sexmale}.\\ 

Now we try something different. First we define \code{"passed"} to be our dependent variable. 
This leads to a binomial regression model which models whether the probability of pass/fail 
depends on certain independent variables. Secondly, we also use country as a predictor (instead 
of a grouping variable). This is to test whether the effect of sex varies across countries. 
To simplify displaying the results, we use the same workaround as in the example before. \\

<<regression2def>>=
mod1  <- jk2.glm(datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", 
         formula = passed~country*sex, family=binomial(link="logit") )
res   <- dG(mod1)
@

Inspecting the output, we found that the probability of success significantly depends on the 
country an examinee stems from and on an examinee's sex. The probability of passing the test
is significantly lower for males and for examinees who stem from \code{"LandB"}. Examinees 
who stem from \code{"LandC"} do not significanty differ in their probability of passing the test 
from examinees who stem from the reference country, \code{"LandA"}. Moreover, the disadvantage of 
boys is not consistent across countries: In \code{"LandB"}, this difference
is significantly less substantial.\\
Please note that---although we have only defined one independent variable---we obtain two 
regression coefficients for the two categories of the country variable. Again, R choosed its 
favorite reference group by itself. The effects are expressed in relation to \code{LandA}. 
To interpretate the effects, the coefficients may be transformed to odds ratios:\\

<<transformdef>>=
exp(mod1[c(1,3,5,7,9),"value"])
@

In \code{LandB} the odds ratio to pass is 0.58 times the corresponding odds ratio in 
\code{LandA}. The following subsections address two little questions one might ask oneself.

\subsection{How to change reference group at costumer's option}
\label{subsec:faq1}

As we saw in the preceding section, R choosed the reference group of factor variables 
by itself. Persuading R to meet our needs is easier said than done. The essentially 
easiest way is to redefine the factor variable and choose its levels manually. We will 
demonstrate this procedure about the gender variable in our fictitious data set. Remember 
the first example in section 3---R choosed the females to be the reference. Why? Simply 
because female comes before male in the alphabet. Let's redefine the gender variable:\\

<<recodeSexdef>>=
readN1[,"sexRecoded"] <- factor(readN1[,"sex"], levels = c("male", "female") )
@

The simple intervention provokes R to use the first label mentioned in the 
\code{levels}-argument as reference group when repeating the last example:\\

<<regressionReplicationdef>>=
mod1  <- jk2.glm(datL = readN1, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", imp = "imputation", 
         formula = passed~country*sexRecoded, family=binomial(link="logit") )
res   <- dG(mod1)
@

\subsection{Which of both determination coefficients should I pay attention?}
\label{subsec:faq2}

The output of each \code{jk2.glm()} analysis also contains the pooled determination coefficient, $R^2$, most frequently 
the conventional $R^2$ and Nagelkerke's $R^2$. However, in linear regression models, i.e. if the identity link is used, 
assuming normally distributed errors, the conventional $R^2$ should be used to interpret explained variance. In log-linear
regression models, i.e. if the binomial link function is used, Nagelkerke's $R^2$ should be used. The reason for reporting 
both coefficients is the programming disability of the package developer. 

\section{Nested imputations}
\label{sec:nested}

The next to last chapter of this little tutorial is reserved to the problem of nested imputation. The general concept is described in
\citet{Rubin2003}. At this point, only some specific aspects which are relevant in large scale assessments, are mentioned briefly. 
Weirich et al. (2014) described the same procedure more elaboratively. Suppose you want to estimate IRT proficiencies 
(often denoted $\theta$) in a specific domain. Applying an extensive marginal model which comprehends of item responses and 
background information as well, the posterior distribution of each examinees' $\theta$ is specified. Without any certain 
proficiency value of a specific examinee, plausible values are drawn from the posterior of each examinee. Conceptually, 
plausible values are multiple imputations of the inherently missing variable $\theta$ and may analyzed in standard statistic 
procedures. To obtain valid estimates and standard errors, the results have to be 
pooled according to \citet{Rubin1987}.\\

Suppose you have missing data in the background variables as well, which have to be imputed in the first step, which may result in 
$M=5$ data sets. For each data set a marginal IRT model is specified and $N=20$ plausible values are drawn. Overall 
$5\times 20=100$ plausible values in a dependency structure will result from the analysis. Formally, we now have nested 
imputed data. To pool the results, the formulas in \citet{Rubin1987} cannot be applied, as the plausible values do not 
stem from a common `nest'. The interdependence has to be taken into account. Whereas the conventional pooling formulas 
split the overall variance in the variance within imputation and the variance between imputation, where the latter one is used 
to estimate the uncertainty due to imputation, the formulas for nested imputation extend the old ones by splitting the variance 
between imputation in the within-nest variance and the variance between nests. See \citet{Rubin2003} for further details. These 
varied formulas are also implemented in \code{eatRep}.\\

If the data analysed with \code{eatRep} stem from a nested multiple imputation structure, this structure has to be specified. 
More specifically, the structure has to be represented in the long-format data frame. \code{eatRep} has to know the number of 
nests and the number of imputations in each nest. The above procedure sounds more complicated than it hopefully is.\\

\subsection{Example: Compute descriptives from a nested imputation structure}
\label{subsec:nest1}

At the beginning of this little tutorial, we have created a subset of our data set which was used for all analyses so far. 
Now it's time to consider the whole data set. The variable \code{"nest"} denotes the nest or first-stage imputation variable. 
As we only have two nests, only two imputations were created in the first step. Within each of this two imputations, three 
plausible values were drawn from the marginal (or conditioning) model. Hence, we would expect that the plausible values 
(captured in column \code{"score"}) vary between nests \emph{and} between imputations, whereas the conditioning variables 
(e.g. income) only vary between nests, but not between imputations within each nest! To date, the \code{eatRep} does not provide
any consistency checks whether this requirements are fulfilled.\\

All analyses specified so far treated 3 imputations. Considering the nested structure now comprises  $3\times 2=6$ imputations. 
For the purpose of illutration, we repeat our very first example, using nested imputations now:\\

<<nestEx2def>>=
means <- jk2.mean(datL = reading, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", nest="nest", imp = "imputation", 
         groups = "country", dependent = "score")
dM(means, omitTerms = c("var", "Ncases", "NcasesValid", "meanGroupDiff"))
@

The only thing we have to change is that we use now the whole data and additionally specify the variable
which denotes the ``nests''.\\

\subsection{Example: Fit a linear regression model in a nested imputation structure}
\label{subsec:nest2}

The principles of considering the nested structure are quite the same as in the preceding example. 
We now want to predict ``reading ability'' by \code{sex} and \code{income}. Using \code{country} 
as group variable likewise allows for investigating whether the potential effects vary across countries.\\

<<nestEx3def>>=
mod1  <- jk2.glm(datL = reading, ID = "idstud", wgt = "wgtSTUD", type = "JK2", 
         PSU = "JKZone", repInd = "JKrep", nest="nest", imp = "imputation", 
         groups = "country", formula = score~sex+income, family=gaussian(link="identity") )
res   <- dG(mod1)
@

%%\section{last chapter}
%%\label{sec:last}

%%The final chapter is designated to provided an example which is closely related to the common practice of 
%%large-scale assessments, for example in the ``Laendervergleich'' studies processed at the 
%%Institute for Educational Quality Improvement (IQB). We use artificial data from Weirich et al. (in press). 
%%First, we have to load the data and two necessary libraries, \code{mice} and \code{eatModel}.\\

%%<<loadLib>>=
%%library(mice)
%%library(eatModel)
%%data(testdata)
%%str(testdata)
%%@

%%Most variables in the dataset will seen familiar to you, with two exeptions: First the \code{sex} and 
%%\code{hisei} variables now have a substantial amount of missing data. Second the data set does not 
%%contain (imputed) values for the corresponding scale (``reading ability'') but only the responses
%%to the items (column \code{"resp"}). Hence, these data might be directly result from the questionnaires
%%in a large-scale assessment. We now would have to impute the missing data on the demographic variables 
%%which we will use afterwards in the conditioning model to obtain the plausible values. Typically, this
%%is done within four steps: 

%%\begin{enumerate}
%%\item The first step is calibration of the items, where we will use a simple unidimensional Rasch model.
%% We want to estimate item parameters on the one hand and a proxy for $\theta$ which is inherently unobserved 
%% in latent measurement models but nevertheless necessary in the imputation model. 
%%\item The second step is imputation of \code{sex} and \code{hisei}. According to a MAR assumption, we 
%% suppose that the probability of a missing response on \code{sex} and \code{hisei} might depend on $\theta$.
%% Hence, $\theta$ should be included in the imputation model. We will generate 5 imputed data sets.  
%%\item The third step is drawing plausible values. Having generated several complete data sets, we specify 
%% the conditioning model on each data set and draw plausible values in each case. 
%%\item The last step is to collect the plethore of plausible values and compute the quantities of interest. 
%%\end{enumerate}

%%In the first step, we reshape the data into the wide format and call \code{defineModel} from the \code{eatModel}
%%package. For the sake of speed, we will use \code{TAM} instead of Conquest for estimation.\\

%%<<calibrate>>=
%%datW <- reshape2::dcast(testdata, idstud+country+sex+hisei+wgtSTUD+JKZone+JKrep~variable, 
%%        value.var = "resp")
%%defM <- defineModel(dat = datW, items = unique(testdata[,"variable"]), id="idstud", 
%%        software="tam")
%%runM <- runModel(defM)
%%@

%%In the second step, we use WLEs scores obtained from the calibration model as an ``auxiliary variable''
%%in the imputation of \code{sex} and \code{hisei}.

%%<<imputation>>=
%%wle  <- tam.wle(runM)
%%datI <- merge(wle[,c("pid", "theta")], datW[,c("idstud", "sex", "hisei")], 
%%        by.x = "pid", by.y = "idstud", all=TRUE)
%%### data set for imputation        
%%dat  <- datI[,-1]
%%toImp<- lapply(dat, FUN = function ( d ) { length(which(is.na(d))) })
%%toImp<- names ( which(toImp > 0) ) 
%%mdp  <- md.pairs( dat )
%%ini  <- mice(dat,  max=0, defaultMethod=c("norm", "logreg", "polyreg"), print = FALSE)
%%imputMethod <- ini$meth   
%%imp.pg      <- mice(dat, meth = imputMethod, m = 5, max=1, seed=10000, printFlag = FALSE)
%%imp.i.pg    <- imp.pg
%%for (iii in 1:10){
%%     imp.i.pg <- mice.mids(imp.i.pg, maxit=1, printFlag = FALSE)}
%%dat.imp <- complete(imp.i.pg,action="long") 
%%dat.imp <- do.call("rbind", by(data = dat.imp, INDICES = dat.imp[,".imp"], FUN = function ( x ) {
%%           return ( data.frame ( datI[,"pid", drop=FALSE], x , stringsAsFactors = FALSE))}))
%%colnames(dat.imp) <- gsub(".imp", "nest", colnames(dat.imp))
%%@

%%We now have five complete data sets. In the third step, the conditioning model is applied on 
%%each data set. This is realized using a ``by''-loop. The item parameters from the 
%%calibration model now are used as anchor parameters. The conditioning model is estimated
%%in each country separately. \\

%%<<conditioning>>=
%%datC <- merge(dat.imp, datW[,c("idstud", "country", "wgtSTUD","JKZone", "JKrep")], 
%%        by.x = "pid", by.y ="idstud", all=TRUE)
%%datC <- by(data = dat.imp, INDICES = dat.imp[,c("nest", "country")], FUN = function ( sub.dat ) {
%%        browser()})
%%@

\bibliography{eatrep}

\end{document}
