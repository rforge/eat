\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{amsmath}
\usepackage{bm}
\usepackage[authoryear,round]{natbib}
\bibliographystyle{plainnat}
\DefineVerbatimEnvironment{Sinput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontshape=sl,
  fontfamily=courier,fontseries=b, fontsize=\scriptsize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontfamily=courier,fontseries=b,%
  fontsize=\scriptsize}
%%\VignetteIndexEntry{eatRep: a package to analyze multiple imputed data in complex survey designs}
%%\VignetteDepends{eatRep}
%%
\newcommand{\trans}{\ensuremath{^\mathsf{T}}}
\newcommand{\invtrans}{\ensuremath{^\mathsf{-T}}}
\title{eatRep: a package to analyze multiple imputed data in complex survey designs}
\author{Sebastian Weirich\\Humboldt University Berlin, Germany}
\begin{document}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,strip.white=true,keep.source=TRUE}
\SweaveOpts{include=FALSE}
\setkeys{Gin}{width=\textwidth}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\package}[1]{\textsf{\small{#1}}}
\maketitle
\begin{abstract}
  Estimation of simple descriptive statistics becomes cumbersome, if the sample cannot be considered to be a 
  (completely) random draw from the population for which descriptives should be interpreted. This occurs in 
  weighted samples or clustered samples. The same is true if the variables of interest stem from a multiple 
  imputation process and occur, for example, as plausible values. In the estimation of standard error, we 
  then have to account for two possible sources of uncertainty: first the uncertainty due to a clustered 
  sample, and second the uncertainty due to multiple imputed data. This tutorial describes some basic 
  analyses to compute descriptives in complex survey designs using the R package \code{eatRep}, which 
  was designed mainly to supply replications methods in R. Such methods are appropriate to analyze both 
  clustered and multiple imputed data as well. To date, the Jackknife-1 (JK1), Jackknife-2 (JK2) and the 
  balanced repeated replicates (BRR) methods are supported. Some functions overlap with methods provided 
  in the computer software WesVar \citep{Westat2000}---in this case the package only allows for executing
  these analyses in R, which may be easier to implement due to a syntax related interface. Some methods 
  in WesVar are not completely implemented in \code{eatRep} yet, for example bootstrapping methods. For 
  bootstrapping, alternative \code{R} packages (e.g. \code{boot}) may be used. However, some methods are 
  only implemented in \code{eatRep}, for example analyses for nested imputed data, linear logistic 
  regression models, or trend analyses. Examples considering the latter one are not yet included 
  in this vignette. The examples 6 to 6d from the help page of the \code{defineModel} function in 
  the \code{eatModel} package contain some exhaustive demonstrations of trend analyses.\\ 
  
  \code{eatRep} heavily relies on the \code{survey} package \citep{Lumley2012} which functions has been extended by methods 
  for multiple imputed data. While the functional principle of \code{survey} is based on replication of conventional 
  analyses, \code{eatRep} is based on replication of \code{survey} analyses to take multiple imputed data into account.
  %%  The following tutorial does not intend to give theoretical foundations nor a critical review of those methods or of anything else. Also, this is 
%%  not an introduction to R.
\end{abstract}

<<preliminaries,echo=FALSE,print=FALSE>>=
library(eatRep)
@

\section{Introduction}
\label{sec:intro}

In a completely random sample, the mean
\begin{equation}
  \label{eq:1}
  %% \bar x= \frac{\sum\limits_{i=1}^n(x_i)}{n}
  \bar x= n^{-1}\sum\limits_{i=1}^n(x_i)
\end{equation}
is an unbiased estimate for the corresponding mean
\begin{equation}
  \label{eq:2}
  %% \mu= \frac{\sum\limits_{i=1}^N(x_i)}{N}
  \mu= N^{-1}\sum\limits_{i=1}^N(x_i)
\end{equation}
of the underlying population the sample was drawn from. This does not hold for dispersion measures (variance and standard
deviation), as the variance in a sample is always less than the variance in the population the sample was drawn from. The transformation,
however, is very easy made: The variance in a sample is multiplied by $n/(n-1)$ to obtain population variance, where $n$ is the sample size.
Based on
\begin{equation}
  \label{eq:3}
  %% \sigma^2= \frac{\sum\limits_{i=1}^N(x_i-\mu)^2}{N}
  \sigma^2= N^{-1}\sum\limits_{i=1}^N(x_i-\mu)^2
\end{equation}
for the population with $N$ elements, we apply
\begin{equation}
  \label{eq:4}
  %% s^2= \frac{\sum\limits_{i=1}^n(x_i-\bar x)^2}{n-1}
  s^2= (n-1)^{-1}\sum\limits_{i=1}^n(x_i-\bar x)^2
\end{equation}
to estimate population variance from a sample of size $n$. In a weighted sample, i.e. if the population weights differ between
examinees in the sample, mean and variance may be estimated by incorporating these population weights.
(In a completely random sample, these weights equal 1 for each examinee.)
\begin{equation}
  \label{eq:5}
  \bar x_w= \sum\limits_{i=1}^n\left(\dfrac{w_i}{W}x_i\right) ,
\end{equation}
\begin{equation}
  \label{eq:6}
   s_{w}^{2}= \sum\limits_{i=1}^n \dfrac{w_i}{W-1}(x_i-\bar x)^2 ,
\end{equation}
%%\begin{equation}
%%  \begin{aligned}
%%  \label{eq:5}
%%  \bar x_w&= \dfrac{\sum\limits_{i=1}^n\left(\dfrac{w_n}{W}x_i\right)}{W}\\
%%  s^2&= \dfrac{\sum\limits_{i=1}^n \dfrac{w_n}{W-1}(x_i-\bar x)^2}{n} \\
%%  s^2&= n^{-1}\sum\limits_{i=1}^n \frac{w_n}{W-1}(x_i-\bar x)^2 ,
%%  \end{aligned}
%%\end{equation}
where $w_i$ is the case weight of the \emph{i}th person, and $W$ is the sum over all case weights, i.e. $W=\sum w_i$.
To summary, the crucial point in the estimation of population variance estimates is the factor $n/(n-1)$. Unfortunately, this factor only
applies when we sample (conditionally) independently from the population, as in completely random samples or weighted
random samples. In a clustered sample, however, where schools or classes are sampling units instead of single persons,
the relationship between sample and population variance is not so clear at all. The reason is that persons \emph{within} a cluster (for
example pupils in a class) often share a common variance. The sample variance underestimates the population variance, but more
severely than indicated by the factor $n/(n-1)$. To estimate the relationship between sample and population variance, it is
necessary to estimate the variance explained by the cluster.\\

Without taking the cluster structure into account, we would not only obtain biased variance estimates but biased 
standard errors, too \citep{luke2009}. This problem occurs in the same way for estimation of frequency tables, 
quantiles or estimates of (linear) regression models. To gain unbiased estimates, several replication methods 
were introduced, which based on the same principle: To estimate the proportion by which the variance in the 
sample is underestimated due to a clustered structure \citep{Lumley2004}. In the Jackknife-2 (JK2) procedure 
this is implemented by reproducing the original sample to several replicates. In each replicate one clustering 
unit (e.g. one class) of only one primary sampling unit (PSU) is replaced by another class, which therefore 
occurs two times in the sample. Each replicate is analyzed if it would have been a completely random sample. 
Recognize what is to be expected then: If the variance is explained partially by the clusters, removing
one sampling unit should decrease the variance of the sample slighty. Conversely, the point estimates of each 
replication sample should vary slightly. The variance in the point estimates between the replicates is used to 
estimate the corresponding standard errors. Otherwise, if there is no variance between clusters, removing one 
cluster would have no effect on the variance estimate, and the point estimates between replicates would have 
no or only very little variance. In this case replication methods will result in exactly the same variance 
estimates and standard errors as they would follow from conventional analysis. The balanced repeated replicates 
(BRR) method is quite similar. The original sample is reproduced to several replicates. In each replicate 
one clustering unit (e.g. one class) \emph{of each PSU} is replaced by another class, which therefore 
occurs two times in the sample. Each replicate then is analyzed if it would have been a completely random sample.
For further details, see Rust and Rao (1996).\\

For the purpose of illustration, assume a simple population mean which has to be estimated from a completely random 
sample of $N=1000$. To estimate the standard error of this mean, we may apply a rather laborious method: to draw 100 
samples (with replacement) from our original sample, each of $N=1000$, and compute the mean in each sample. The standard 
deviation of the 100 mean estimates is the standard error of the mean. Of course, this bootstrap method is far to 
cumbersome, as in a random sample the standard error can be estimated in a much more easier way. However, in a 
clustered sample, an extension of this bootstrap method is appropriate indeed.
Several software \citep{Westat2000} and free R packages such as \code{survey} \citep{Lumley2012}
do allow for several replication methods.\\

The situation is becoming still more complicated when the variables in the data to be analysed occur as (multiple) 
imputed data, for example as plausible values. Where missing values may cause biased parameters, analyses are conducted with 
imputed data. Often, the original data which includes missing values is reproduced several times, whereas the missing entries 
are filled with a set of plausible values, which results in several imputed data sets. 
To gain unbiased parameter estimates, the analyses are conducted for each data set 
separately and pooled afterwards according to \citet{Rubin1987}.\\

If we have both, a clustered sample with multiple imputed data, both methods have to be combined. This leads to a replication
of replications. Analyses have to be repeated to account for the clustered structure, and the results of these replications 
have to be repeated to account for multiple imputed data. In the following, we refer to ``cluster replicates'' 
and ``imputation replicates'' to differentiate between both.

\section{Estimate some population descriptives}
\label{sec:ex1}
In this example, we use some artificial data from the context of educational research. We may think of a stratified clustered 
sample of German fourth-grade primary school students whose reading and listening competencies are measured. Proficiency estimates
obtained from a Item response Theory (IRT) marginal model are included as plausible values. Each plausible value may be 
recognized as an imputation of the latent competence construct. The data are represented in the long format.\\ 

<<reading_writingdef>>=
library(eatRep)
data(lsa)
str(lsa, give.attr = FALSE)
@

Requesting the data structure provides us with information about the number and type of variables and the number of
examinees. \code{"idstud"} denotes the year of the assessment, \code{"idstud"} is a person identifier for 7,518 distinct
examinees, and \code{"wgt"} a person weight. \code{"JKZone"} and \code{"JKrep"} denote jackknifing variables which contains
information about which unit has to be replaced by which other unit in which replicate of the original data. The next
two variables, \code{"imp"} and \code{"nest"} describe the multiple imputed structure of the data. The data
stem from a nested multiple imputation model with 2 nests and 3 imputations in each nest. The principles of nested
imputations will be elucidated later; for the moment, we may content ourself with data from the first nest only,
i.e. we split the data and only consider cases for which $nest=1$. \code{"country"} denotes the country the person stems
from, \code{"sex"} denotes each person's sex, \code{"ses"} is each person's socio-economical status, \code{"mig"} is an
indicator for migration background. \code{"domain"} denotes whether the corresponding score value is related to
reading or listening. We may think of \code{"score"} as the the plausible value estimate for the reading or listening
competence. Hence, if $nest=1$ and $imputation=3$ and \code{"domain"} equals "reading", the value in the
\code{"score"} column refers to the third plausible value in the first nest for the reading competence. 
\code{"comp"} is a distinct competence level for each person, where 1 corresponds to the lowest competence
level, and 5 corresponds to the highest competence level. \code{"failMin"} is an indicator which equals 1
if the examinee fails to fulfill the minimal standard, 0 otherwise. \code{"passReg"} is an indicator which equals 1
if the examinee fulfills or outperforms the regular standard, and \code{"passOpt"} is an indicator which equals 1
if the examinee fulfills the optimal standard. The following variables beginning with "le" denote the linking
errors of each criteria, i.e. \code{"lePassreg"} is the linking error for the indicator of fulfilling the
regular standard.

Please note that the \code{"score"} variable contains the three imputations of the reading competence.
Hence, each individual is represented in several rows. This is quite usual if multiple imputed data is 
presented in a long format dataset. \code{eatRep} strictly requires the long format. To transform wide-format
data frame into long-format data frames (and vice versa), use the \code{reshape2} package. Please note further 
that the dataset does not contain any replicates, only the information required for generating them are captured
in the \code{"JKZone"} and \code{"JKrep"} variables. 

\subsection{Populations means, standard deviations, variances and mean differences}
\label{subsec:means}

We now want to compute the means by each country, considering the clustered structure as well as the multiple 
imputed data structure. The replicates do not need to be created separately, as they will be generated in each 
analysis automatically. Even in large data sets this takes only a few seconds. First we create a subset which 
only contains reading data from the first nest from the year 2010. The analysis then is conducted with this subset.\\

<<readingMeansByCountrydef>>=
read  <- subset(lsa, domain == "reading")
readN1<- subset(read, nest == 1 )
read10<- subset(readN1, year == 2010 )
means <- jk2.mean(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = "country",
         dependent = "score")
@

When applying the jackknife method, the primary sampling unit (PSU) often is the jackknife zone (jkzone),
and the replication indicator often is the jackknife replicate indicator (jkrep). While the function is operating,
some additional information is displayed on console. First we see that only one analysis is run according to
\code{'group.splits = 1'}. We will subsequently exemplify this enigmatic message. Further, we see that \code{jk2.mean}
assumes an ``unnested'', i.e. a structure with three imputations. This refers to what we've called 
``imputation replicates''. The output then speaks about 62 replicate weights which are created due to 62 distinct
jackknifing zones in the JKZone variable. This information refers to the ``cluster replicates'' and implies that 
the subsequent analysis has to be repeated 62 times \emph{for each imputation}. Hence, $3\times 62=186$ analyses are
run overall.\\ 

In each of the 62 replication samples, one unit (e.g. school) of a certain jackknifing zone is missing and the weights
of the other school within the same zone are doubled. The data in all other zones remain unchanged. The analyses are
repeated 62 times, \emph{using the same plausible value} as the dependent variable. Only the weights vary between the
``cluster replicates'': each of the 62 replicates once a time is used as the weighting variable. Each of the 62
analysis revealed slighty different results. This variation is used to estimate the sampling variance 
\emph{due to the clustered structure} which then is used to compute the standard error, which is pooled across 
62 ``cluster replicates''. When finished, the analysis approaches the second ``imputation replicate'' and switches
to the second plausible value which now is used as the dependent variable in 62 analyses due to the
62 ``cluster replicates''. After all, three pooled estimates and three pooled standard errors resulted
which differ slightly in each ``imputation replicate''. The three estimates and standard errors are pooled 
once again, this time according to \citet{Rubin1987}. To sum up, the pooled results are pooled again to account for 
both: multiple imputed data in a clustered sample.\\

The little dots continuously appearing on the console therefore refer to ``imputation replicates'' and are intended 
to work as a rough progress bar. Each dot represents one ``imputation replication''. When the procedure finished, 
the results are pooled in the case of more than one imputation.\\

The output is a list of data frames which is not intended to be inspected by the user. Instead, a reporting
function transform the raw output in a more user-friendly format which can be saved as an Excel or csv
file for further treatment. The reporting function has an additional argument \code{add} which can be used
to ``enrich'' the output by further columns which contain, for example, the domain. The raw output does not
include any information about the domain. The reporting function may be used as follows:\\

<<reporting01>>=
res01 <- report(jk2.out = means, add = list(domain = "reading"))
print(res01, digits = 4)
@

For each subpopulation denoted by the \code{groups} statement (here: \code{LandA}, \code{LandB} and \code{LandC}),
each dependent variable (here: only the reading competence "score"), each parameter and each coefficient (i.e., the
estimate and the corresponding standard error) the corresponding value is given. Can we see see how the results would
change if we do not consider the clustered structure? Yes, we can. We simply leave out the jackknifing arguments
\code{JKZone} and \code{JKrep}. The type argument then is automatically ignored likewise, whether
specified or not. The results will be pooled only due to multiple imputed data:\\

<<readingMeansByCountry2def>>=
means <- jk2.mean(datL = read10, ID = "idstud", wgt = "wgt",
         imp = "imp", groups = "country", dependent = "score")
res02 <- report(jk2.out = means, add = list(domain = "reading"))
print(res02, digits = 4)
@

We see that the means are completely unaffected, but the standard errors for the mean
estimates are considerably lower. (Standard errors for standard deviations are not
implemented yet.) If we decide to leave out the weights as well,
we would additionally expect to receive different means now:\\

<<readingMeansByCountry3def>>=
means <- jk2.mean(datL = read10, ID = "idstud", imp = "imp", groups = "country",
         dependent = "score")
res03 <- report(jk2.out = means, add = list(domain = "reading"))
print(res03, digits = 4)
@

If we additionally decide to ignore the imputations and treat, for example, the first plausible value as it would have been 
a fully observed measure of the latent competency, the function call would be the following:\\

<<readingMeansByCountry4def>>=
means <- jk2.mean(datL = subset(read10,imp==1),  ID = "idstud",
         imp = "imp", groups = "country", dependent = "score")
res04 <- report(jk2.out = means, add = list(domain = "reading"))
print(res04, digits = 4)
@

The estimation of standard errors now no longer accounts for the uncertainty due to imputation. Furthermore, also the 
mean estimates have changed as the estimation now is based only on the first plausible value. \\

Two possible interesting features should be emphasized in the following. First assume that we do not have one, but two
grouping variables, namely \code{country} and \code{sex}. As we have three countries and two sex values, 
the whole population is splitted into $3\times 2=6$ subpopulations for which descriptives can be requested. If we 
additionally are interested in the descriptives of the whole population or the descriptives 
\emph{within each country, but together for both sex groups}, we can use the \code{group.splits} argument to 
particularly specify the groups we are interested in. Let us consider for example the two grouping variables 
\code{country} and \code{sex}. If \code{group.splits} equals 2 (the default, i.e., the number of grouping 
variables), descriptives for the $3\times 2=6$ subpopulations are computed. If \code{group.splits} 
is \code{1:2}, descriptives for each country (e.g., across sex) and each sex group (e.g. across countries) 
additionally are computed. If \code{group.splits} is \code{0:2}, descriptives also for the whole population 
(e.g. across sex \emph{and} countries) are computed. \\

The second feature is about mean differences. Suppose you are interested in sex differences \emph{within} each 
country. The grouping variable for which mean differences should be computed has to be specified in 
the \code{group.differences.by} argument. For a grouping variable with $K$ levels, all $K!/(2!\times(K-2)!)$ comparisons
are computed. It is important that the group defined in \code{group.differences.by} also has to occur in the \code{groups} 
statement, otherwise \code{group.differences.by} will be ignored. To estimate sex differences \emph{within each 
country}, sex and country have to be part of the \code{groups} statement, whereas only sex has to be
used in the \code{group.differences.by} argument. Both features are illustrated in the following example:\\

<<readingMeansByCountry4def>>=
means <- jk2.mean(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = c("sex","country"),
         group.splits = c(0,2), group.differences.by = "sex", dependent = "score")
res05 <- report(jk2.out = means, add = list(domain = "reading"))
print(res05, digits = 4)
@

First note the \code{group.splits} is set to \code{c(0,2)}, which means that we request descriptives for the whole
population and the 6 subpopulations. Consequently, two analyses are conducted. The \code{group.differences.by} only
applies for the second analysis, as the gender group is not considered relating to the whole population analysis. 
To estimate sex differences \emph{across all countries}, only sex has to be part of the \code{group} statement, 
and only sex has to be used in the \code{group.differences.by} argument. The output of the analysis is nearly the 
same as we would have omitted the \code{group.differences.by} argument, but now, some additional lines have joined. 
Additionally to several group columns, one column for group membership is provided.
The last line labelled \code{wholeGroup} provides results concerning the whole population. The line labelled 
\code{male\_LandC} contains values for the males in LandC. Moreover, three mean differences were computed. In each
federal state, the difference between males and females is given. \\

At last for this chapter, let's consider a further comparison: We see group differences
according to \code{sex} in each country. It is plausible to assume that there are group
differences also in the whole population. But: Is there any country for which the group
differences differ substantially from the group differences in the whole population? To
investigate this, we make an exception from the rule that \code{group.differences.by}
must contain values which are included in \code{groups}: We add the term \code{wholePop}
into the argument \code{group.differences.by}:\\

<<read5def>>=
means <- jk2.mean(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = c("sex","country"),
         group.splits = 0:2, group.differences.by = "sex", cross.differences = TRUE,
         dependent = "score")
res06 <- report(jk2.out = means, add = list(domain = "reading"))
@

We see in the first line of the \code{results} object that the group differences in 
the whole population are -27.39 points. Line number 2 includes the group differences 
in \code{LandA}, which amounts -34.53. The difference between both, 
i.e. $-34.53-(-27.39)=-7.14$ is contained in line 3. Considering the 
corresponding standard error of 8.7 yields that the difference is not significant:
The amount of the deviation (7.13) is less than twice the standard error of the amount.\\

\subsection{Frequency tables}
\label{subsec:freqs}

Computation of frequency tables works in the same manner as in the examples mentioned before. 
Representative for several possible analyses only one example is given below. Consider the 
\code{score} column we used as the dependent variable in all previous analyses. Suppose we
define a cut score criterion, i.e. all persons with at least 465 points passed, the other
ones failed. The indicator variable \code{passReg} defines whether the ``regular standard''
was fulfilled or not. We now may be interested whether the percentage of pass/fails differs between
countries. We henceforward consider the column \code{passReg} as dependent variable which is
a simple indicator, i.e. a categorical variable with two categories (computation of frequency 
tables for variables with more than two categories are possible, too). Categorical variables 
are often represented as factors in R, which is quite straightforward. However, the 
\code{passReg} variable is of class numeric. This is an inconsistency which may cause annoying
misinterpretations when such variables are called in functions related to the generalized linear 
model like \code{aov()}, \code{glm()} etc. For the computations of frequency tables it is not 
necessary to convert the variable class to factor.\\ 

We now are interested in the relative frequencies of this groups in the different countries 
and within each country for different groups of gender. As before, we want to take the cluster 
structure and multiple imputations into account. Moreover, we are interested whether the distribution 
of pass/fail is different for males vs. females within specific countries. This is done via a chi 
square test. The test statistic is pooled according to the clustered structure and the imputations. 
To call for the chi square test, we can use the \code{group.differences.by} argument and additionally
specify \code{chiSquare = TRUE}:\\

<<hiseiFreqsByCountryGenderdef>>=
freqs <- jk2.table( datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = c("country", "sex"),
	       group.differences.by = "sex", chiSquare = TRUE, dependent = "comp")
res07 <- report(jk2.out = freqs, add = list(domain = "reading"))
print(res07, digits = 4)
@

The reporting function \code{report} summarizes the results.

The output is a single data frame in the long format. To make the output more pleasing to the 
eye, a short summary function \code{dT} is just waiting to do her job, to summarize the results.
The first column refers to the groups specified in the analysis (in our example: 
\code{country} and \code{sex}). The next column gives the name of the dependent variable 
(i.e. ``passReg''). The ``modus'' simply tells which analysis was conducted. If a specific
kind of comparison was computed, the ``comparison'' columns gives information whether group
differences, cross level differences or cross level differences of group differences were
computed. The ``labels'' of the dependent variable now are captured in the \code{parameter} column.
We see that in country \code{"LandA"} 73.1 percent of the females and 67.7 percent of the males
fulfills the regular standard. The first three lines of the output indicate that in all countries
the percentage of females fulfilling the standards exceeds the percentage of males. The differences,
however, is non significant in each country.\\

Unfortunately, the results of the chi square test are not yet captured by the \code{report} function,
so we have to extract them from the \code{freqs} object by ourself:\\

<<hiseiFreqsExtraction>>=
options(scipen=4)
cols <- c("group", "coefficient", "value")
frqs <- freqs[["resT"]][["noTrend"]]
res  <- frqs[which(frqs[,"parameter"] == "chiSquareTest"), cols ]
wide <- reshape2::dcast(res, group~coefficient, value.var = "value")
wide <- wide[,-grep("Approx", colnames(wide))]
print(wide, digits = 1)
@

In each of the three countries a chi square test was conducted separately. For \code{LandA}, 
the \emph{p} is <.001, hence the distribution of passed/failed significantly differs between 
males and females in \code{LandA}. However, \code{LandB} and \code{LandC} reveals another 
picture---there are no sex differences in the rate of pass/fail. As we have imputed data, 
we additionally have an chi square approximation. See the help page of \code{micombine.chisquare}
of the \code{miceadds} package for further details. \\

There is a second alternative to analyze whether the distribution of pass/fail is different for 
males vs. females within specific countries. With \code{chiSquare = FALSE} we get the 
differences \emph{separately for each category} of the dependent variable within each country.
The conclusion we draw from this analysis, however, is quite equivalent to the preceding analysis: \\

<<hiseiFreqsByCountryGenderdef2>>=
freqs <- jk2.table( datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = c("country", "sex"),
	       group.differences.by = "sex", chiSquare = FALSE, dependent = "passReg")
@

Let's devote little attention to the problem of missing values. In the example mentioned above, 
it does not seem plausible to assume missing values on the \code{"passed"} variable. Without
available data for an examinee, the case will be excluded from the data previously. But consider 
a questionnaire where pupils are asked about there parents' profession, for example to compute 
the family's highest socio-economical income (HISEI). Some examinees might have choosen the 
option ``I don't know my parents' profession''. Conceptually, it makes considerably more 
sense to define a separate category during the data preparation, for example ``lowest HISEI'', 
``medium HISEI'', ``highest HISEI'', ``unknown HISEI''. Families without valid
HISEI information then will be considered as a separate group in the analyses. Applying 
\code{jk2.table} then will give frequencies for four groups. However, if the ``Dont't know'' 
cases appear as ``NA'' values, \code{eatRep} has to know whether it should handle these values
as missing or as a new distinct category named ``Dont't know'' (or whatever), for which 
relative frequencies also can be computed. Only for illustration, let us generate some missing values 
in some of the imputations and repeat the analysis subsequently. You will see that a new category 
has joined to the output, which is labelled \code{"<NA>"}. \\

<<redefineValues2def>>=
read10[,"passedNA"] <- read10[,"passReg"]
read10[ sample(nrow(read10), 100, FALSE) ,"passedNA"]   <- NA
freqs2<- jk2.table( datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = c("country", "sex"),
	       dependent = "passedNA", separate.missing.indicator = TRUE)
@

\subsection{Quantiles}
\label{subsec:quantiles}

Estimation of quantiles for numerical variables is possible using the function 
\code{jk2.quantile}. All related analyses mentioned up to this point apply in the 
same way. Note that these analyses apply for numerical dependent variables. 
See the examples in the help file of \code{jk2.quantile()}.\\

\section{Generalized linear models}
\label{sec:ex2}

Considering multiple imputations and clustered structure in the estimation of generalized 
linear models is based on the same principles as aforementioned. However, some additional 
comments due to specific characteristics of regression models have to be made. First we 
now have another type of variable---independent variables, which may occur as multiple 
imputed variables, too. Second, we have to specify the regression expression, as in 
\code{glm()}, for example. Third, we will have to specify the kind of regression we 
propose to estimate, for example linear or logistic regression. We start with a simple 
example using the same data as before.\\

<<regression1def>>=
mod1  <- jk2.glm(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = "country",
         formula = score~sex*ses, family=gaussian(link="identity"), poolMethod = "scalar")
@

As we might have expected, the outcome is a single data frame in the long format. 
And long really means long! For our purpose, it may be sufficient to content ourself 
with the summary provided by \code{dG}. But beforehand let us consider how many regression 
analyses are conducted and how many results we expect to find. The message on the console 
speaks of about ``1 analysis overall'' according to \code{group.splits = 1}. But strictly
speaking, we have estimated three regression analyses, as the model is fitted in each group
(i.e., in each country) separately. As we have specified one grouping variable dividing the data into
three distinct groups (according to \code{country}) for which we have instructed \code{jk2.glm()} 
to fit the regression model separately, we find results of the three models in the results. 
More specifically, for each country, an intercept and three regression coefficients according to
\code{gender}, \code{INCOME} and their interaction are estimated. The \code{dG()} function allows
us to have a look only at a specific result out of the 3 analyses. \code{analyses = 1:2} advises
the function to display the results of the first and second analysis. First we should consider
that each single analyses is characterized by two variables, the group for which the model is
fitted, and the dependent variable. In the heading we find information about both. The actual
regression results are displayed underneath. \\

<<regression1defResults1>>=
res   <- report(mod1, printGlm = TRUE)
@

Remember what was said about factors in the chapter about frequency tables: The gender variable 
now has to be defined explicitly to be of class factor! Otherwise, albeit gender variable may be 
coded as 0/1, it would be treated to be a continuous numeric variable. With only two levels---male 
and female---this may have no effect on the results, but consider a factor variable with three 
levels, which may be coded 0, 1 and 2. We are interested in two coefficients which correspond to 
the effect of level 1 vs. level 0 and the effect of level 2 vs. level 0. If we refrain from defining 
the variable to be of class factor, only one coefficient is computed, and the variable is assumed to 
be continuous. What we see additionally is that R implicitly defined the female group to be the 
reference---the regression parameter was labelled \code{sexmale}.\\ 

Now we try something different. First we define \code{"passed"} to be our dependent variable. 
This leads to a binomial regression model which models whether the probability of pass/fail 
depends on certain independent variables. Secondly, we also use country as a predictor (instead 
of a grouping variable). This is to test whether the effect of sex varies across countries. 
To simplify displaying the results, we use the same workaround as in the example before. \\

<<regression2def>>=
mod1  <- jk2.glm(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp",
         formula = passReg~country*sex, family=binomial(link="logit") )
res   <- report(mod1, printGlm = TRUE)
@

Inspecting the output, we found that the probability of success significantly depends on the 
country an examinee stems from and on an examinee's sex. The probability of passing the test
is significantly lower for males and for examinees who stem from \code{"LandB"}. Examinees 
who stem from \code{"LandC"} do not significanty differ in their probability of passing the test 
from examinees who stem from the reference country, \code{"LandA"}. Moreover, the disadvantage of 
boys is not consistent across countries: In \code{"LandB"}, this difference
is significantly less substantial.\\

Please note that---although we have only defined one independent variable---we obtain two 
regression coefficients for the two categories of the country variable. Again, R choosed its 
favorite reference group by itself. The effects are expressed in relation to \code{LandA}. 
To interpretate the effects, the coefficients may be transformed to odds ratios:\\

<<transformdef>>=
#exp(mod1[c(1,3,5,7,9),"value"])
@

In \code{LandB} the odds ratio to pass is 0.58 times the corresponding odds ratio in 
\code{LandA}. The following subsections address two little questions one might ask oneself.

\subsection{How to change reference group at costumer's option}
\label{subsec:faq1}

As we saw in the preceding section, R choosed the reference group of factor variables 
by itself. Persuading R to meet our needs is easier said than done. The essentially 
easiest way is to redefine the factor variable and choose its levels manually. We will 
demonstrate this procedure about the gender variable in our fictitious data set. Remember 
the first example in section 3---R choosed the females to be the reference. Why? Simply 
because ``female'' comes before ``male'' in the alphabet. Let's redefine the gender variable:\\

<<recodeSexdef>>=
read10[,"sexRecoded"] <- factor(read10[,"sex"], levels = c("male", "female") )
@

The simple intervention provokes R to use the first label mentioned in the 
\code{levels}-argument as reference group when repeating the last example:\\

<<regressionReplicationdef>>=
mod1  <- jk2.glm(datL = read10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", imp = "imp",
         formula = passReg~country*sexRecoded, family=binomial(link="logit") )
res   <- report(mod1, printGlm = TRUE)
@

\subsection{Which of both determination coefficients should I pay attention?}
\label{subsec:faq2}

The output of each \code{jk2.glm()} analysis also contains the pooled determination 
coefficient, $R^2$ and Nagelkerke's $R^2$, which may be considered as a pseudo-$R^2$
for log-linear regression models. In linear regression models, i.e. if the identity link 
is used and normally distributed errors are assumed, the conventional $R^2$ should be used 
to interpret explained variance. In log-linear regression models, i.e. if the binomial link 
function is used, Nagelkerke's $R^2$ may be used instead. 

\section{Nested imputations}
\label{sec:nested}

The next to last chapter of this little tutorial is reserved to the problem of nested 
imputation. The general concept is described in \citet{Rubin2003}. At this point, only 
some specific aspects which are relevant in large scale assessments, are mentioned 
briefly. Suppose you want to estimate IRT proficiencies (often denoted $\theta$) in a 
specific domain. Applying an extensive marginal model which comprehends of item responses 
and background information as well, the posterior distribution of each examinees' $\theta$ 
is specified. Without any certain proficiency value of a specific examinee---remember that 
$\theta$ is considered to be latent, i.e. an inherently missing variable---, plausible 
values are drawn from the posterior of each examinee. Conceptually, plausible values are 
multiple imputations of the missing variable $\theta$ and may analyzed in standard statistic 
procedures. To obtain valid estimates and standard errors, the results have to be 
pooled according to \citet{Rubin1987}.\\

Suppose you have missing data in the background variables as well, which have to be imputed 
in the first step, which may result in $M=5$ data sets. For each data set a marginal IRT 
model is specified and $N=20$ plausible values are drawn. Overall $5\times 20=100$ plausible 
values in a dependency structure will result from the analysis. Formally, we now have nested 
imputed data. To pool the results, the formulas in \citet{Rubin1987} cannot be applied, as the 
plausible values do not stem from a common `nest'. The interdependence has to be taken into 
account. Whereas the conventional pooling formulas split the overall variance in the variance 
within imputation and the variance between imputation (where the latter one is used to estimate 
the uncertainty due to imputation), the formulas for nested imputation extend the old ones by 
splitting the variance between imputation in the within-nest variance and the variance between 
nests. See \citet{Rubin2003} for further details. These varied formulas are also implemented 
in \code{eatRep}.\\

If the data analysed with \code{eatRep} stem from a nested multiple imputation structure, this 
structure has to be specified. More specifically, the structure has to be represented in the 
long-format data frame. \code{eatRep} has to know the number of nests and the number of 
imputations in each nest. The above procedure sounds more complicated than it hopefully is.\\

\subsection{Example: Compute descriptives from a nested imputation structure}
\label{subsec:nest1}

At the beginning of this little tutorial, we have created a subset of our data set which was 
used for all analyses so far. Now it's time to consider the whole data set. The variable 
\code{"nest"} denotes the nest or first-stage imputation variable. As we only have two nests, 
only two imputations were created in the first step. Within each of this two imputations, three 
plausible values were drawn from the marginal (or conditioning) model. Hence, we would expect 
that the plausible values (captured in column \code{"score"}) vary between nests \emph{and} 
between imputations, whereas the conditioning variables (e.g. income) only vary between nests, 
but not between imputations within each nest! To date, the \code{eatRep} does not provide
any consistency checks whether this requirements are fulfilled.\\

All analyses specified so far treated 3 imputations. Considering the nested structure now comprises  $3\times 2=6$ imputations. 
For the purpose of illutration, we repeat our very first example, using nested imputations now:\\

<<nestEx2def>>=
read      <- subset(lsa, domain == "reading")
readN1.10 <- subset(read, year == 2010 )
means <- jk2.mean(datL = readN1.10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", nest="nest", imp = "imp",
         groups = "country", dependent = "score")
res   <- report(means)
@

The only thing we have to change is that we use now the whole data and additionally specify the variable
which denotes the ``nests''.\\

\subsection{Example: Fit a linear regression model in a nested imputation structure}
\label{subsec:nest2}

The principles of considering the nested structure are quite the same as in the preceding example. 
We now want to predict ``reading ability'' by \code{sex} and \code{income}. Using \code{country} 
as group variable likewise allows for investigating whether the potential effects vary across countries.\\

<<nestEx3def>>=
mod1  <- jk2.glm(datL = readN1.10, ID = "idstud", wgt = "wgt", type = "JK2",
         PSU = "jkzone", repInd = "jkrep", nest="nest", imp = "imp",
         groups = "country", formula = score~sex+ses, family=gaussian(link="identity") )
res   <- report(mod1)
@


%% Trend analyses

%%\section{last chapter}
%%\label{sec:last}

%%The final chapter is designated to provided an example which is closely related to the common practice of 
%%large-scale assessments, for example in the ``Laendervergleich'' studies processed at the 
%%Institute for Educational Quality Improvement (IQB). We use artificial data from Weirich et al. (in press). 
%%First, we have to load the data and two necessary libraries, \code{mice} and \code{eatModel}.\\

%%<<loadLib>>=
%%library(mice)
%%library(eatModel)
%%data(testdata)
%%str(testdata)
%%@

%%Most variables in the dataset will seen familiar to you, with two exeptions: First the \code{sex} and 
%%\code{hisei} variables now have a substantial amount of missing data. Second the data set does not 
%%contain (imputed) values for the corresponding scale (``reading ability'') but only the responses
%%to the items (column \code{"resp"}). Hence, these data might be directly result from the questionnaires
%%in a large-scale assessment. We now would have to impute the missing data on the demographic variables 
%%which we will use afterwards in the conditioning model to obtain the plausible values. Typically, this
%%is done within four steps: 

%%\begin{enumerate}
%%\item The first step is calibration of the items, where we will use a simple unidimensional Rasch model.
%% We want to estimate item parameters on the one hand and a proxy for $\theta$ which is inherently unobserved 
%% in latent measurement models but nevertheless necessary in the imputation model. 
%%\item The second step is imputation of \code{sex} and \code{hisei}. According to a MAR assumption, we 
%% suppose that the probability of a missing response on \code{sex} and \code{hisei} might depend on $\theta$.
%% Hence, $\theta$ should be included in the imputation model. We will generate 5 imputed data sets.  
%%\item The third step is drawing plausible values. Having generated several complete data sets, we specify 
%% the conditioning model on each data set and draw plausible values in each case. 
%%\item The last step is to collect the plethore of plausible values and compute the quantities of interest. 
%%\end{enumerate}

%%In the first step, we reshape the data into the wide format and call \code{defineModel} from the \code{eatModel}
%%package. For the sake of speed, we will use \code{TAM} instead of Conquest for estimation.\\

%%<<calibrate>>=
%%datW <- reshape2::dcast(testdata, idstud+country+sex+hisei+wgtSTUD+JKZone+JKrep~variable, 
%%        value.var = "resp")
%%defM <- defineModel(dat = datW, items = unique(testdata[,"variable"]), id="idstud", 
%%        software="tam")
%%runM <- runModel(defM)
%%@

%%In the second step, we use WLEs scores obtained from the calibration model as an ``auxiliary variable''
%%in the imputation of \code{sex} and \code{hisei}.

%%<<imputation>>=
%%wle  <- tam.wle(runM)
%%datI <- merge(wle[,c("pid", "theta")], datW[,c("idstud", "sex", "hisei")], 
%%        by.x = "pid", by.y = "idstud", all=TRUE)
%%### data set for imputation        
%%dat  <- datI[,-1]
%%toImp<- lapply(dat, FUN = function ( d ) { length(which(is.na(d))) })
%%toImp<- names ( which(toImp > 0) ) 
%%mdp  <- md.pairs( dat )
%%ini  <- mice(dat,  max=0, defaultMethod=c("norm", "logreg", "polyreg"), print = FALSE)
%%imputMethod <- ini$meth   
%%imp.pg      <- mice(dat, meth = imputMethod, m = 5, max=1, seed=10000, printFlag = FALSE)
%%imp.i.pg    <- imp.pg
%%for (iii in 1:10){
%%     imp.i.pg <- mice.mids(imp.i.pg, maxit=1, printFlag = FALSE)}
%%dat.imp <- complete(imp.i.pg,action="long") 
%%dat.imp <- do.call("rbind", by(data = dat.imp, INDICES = dat.imp[,".imp"], FUN = function ( x ) {
%%           return ( data.frame ( datI[,"pid", drop=FALSE], x , stringsAsFactors = FALSE))}))
%%colnames(dat.imp) <- gsub(".imp", "nest", colnames(dat.imp))
%%@

%%We now have five complete data sets. In the third step, the conditioning model is applied on 
%%each data set. This is realized using a ``by''-loop. The item parameters from the 
%%calibration model now are used as anchor parameters. The conditioning model is estimated
%%in each country separately. \\

%%<<conditioning>>=
%%datC <- merge(dat.imp, datW[,c("idstud", "country", "wgtSTUD","JKZone", "JKrep")], 
%%        by.x = "pid", by.y ="idstud", all=TRUE)
%%datC <- by(data = dat.imp, INDICES = dat.imp[,c("nest", "country")], FUN = function ( sub.dat ) {
%%        browser()})
%%@

\bibliography{eatrep}

\end{document}
