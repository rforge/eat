\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{amsmath}
\usepackage{bm}
\usepackage[authoryear,round]{natbib}
\bibliographystyle{plainnat}
\DefineVerbatimEnvironment{Sinput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontshape=sl,
  fontfamily=courier,fontseries=b, fontsize=\scriptsize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}
{formatcom={\vspace{-2.5ex}},fontfamily=courier,fontseries=b,%
  fontsize=\scriptsize}
%%\VignetteIndexEntry{eatModel: framework to run IRT models within R}
%%\VignetteDepends{eatmodel}
%%
\newcommand{\trans}{\ensuremath{^\mathsf{T}}}
\newcommand{\invtrans}{\ensuremath{^\mathsf{-T}}}
\title{eatModel: framework to run IRT models within R}
\author{Sebastian Weirich\\Humboldt University Berlin, Germany}
\begin{document}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,strip.white=true,keep.source=TRUE}
\SweaveOpts{include=FALSE}
\setkeys{Gin}{width=\textwidth}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\package}[1]{\textsf{\small{#1}}}
\maketitle
\begin{abstract}
  The software Conquest (Wu, Adams, Wilson, & Haldane, 2007) is a computer program for fitting
  item response and latent regression models. It is based on the Muldi-dimensional mixed-Coefficients
  Multinomial Logit Model, which is a generalized form of the Rasch Model (Adams & Wu, 2007). For
  example, Conquest allows for the estimation of the Rasch model, the rating scale model, the
  partial credit model, the linear logistic test model, multifacet models, multidimensional and
  latent regression models.\\

  Like Mplus, the interface of Conquest is command-line (cmd) based, where the syntax, the data and
  fixed effects indicator names (i.e., names of items) have to be provided in separated ASCII files.
  The package \code{eatModel} was created to allow for more fail-save, less cumbersome
  specification of IRT models in R, which subsequently can be estimated in Conquest.\\
  
  Basically, \code{eatModel} is useful for Conquest analyses calling from R. As the R package
  \code{TAM} can be seen as an extended ``rebuild'' of the Conquest model in an R environment,
  \code{eatModel} allows all models to be estimated in \code{TAM} likewise. However, some model
  specifications (for example, 2PL/3PL) lead to models only TAM is able to estimate. Conversely,
  some other model specifications (for example, partial credit models with many categories or
  differential item functioning) might be unstable in TAM.\\

  Historically, \code{eatModel} is a ``reboot'' of the package \code{eatRest} formerly known as
  \code{eat}. The functionality of both packages is quite identical, whereas \code{eatModel} uses some
  more efficient routines, though. Important note: For consistency reasons, some functions in \code{eatModel}
  have identical names as the corresponding function in \code{eatRest}, for example 'get.shw'. It is strongly
  recommended to \emph{not} have both packages attached simultaneously in one R session.\\
  
  This vignette demonstrates some examples how to specify and estimate several IRT models with \code{eatModel}.
\end{abstract}

<<preliminaries,echo=FALSE,print=FALSE>>=
library(eatModel)
@

\section{Introduction}
\label{sec:intro}

Assume a data set recorded in the context of large-scale assessments. As an example, the package provides IRT
data which contains item responses of 420 examinees to 185 items. The items fall under three basic subjects---namely
biology, chemistry and physics, and are allocated either to the domain ``knowledge'' or ``procedural''. As the data
contains person and item characteristics at once, it is presented in the long format.\\

<<intro01>>=
library(eatModel)
library(reshape2)
data(sciences)
str(sciences)
@

Requesting the data structure provides us with information about the number and type of variables and the number of
examinees. Each line of the data corresponds to one single response of a specific examinee to a specific item.
\code{"id"} is a person identifier for 420 distinct examinees, \code{"grade"} is the class level the person belongs
to, e.g. a person grouping variable, \code{"sex"} denotes each person's sex (also a person grouping variable), 
\code{"booklet"} is the identifier of the booklet the person was provided with, \code{"track"} denotes the kind 
of school track the examinee belongs to, \code{"versions"} denotes whether the person received a booklet with 
rather easy, moderate or hard tasks. \code{"variable"} is an item identifier, and \code{"value"} denotes whether 
the examinee has responded correct (``1'') or incorrect (``0'') to the item. \code{"subject"} specifies the 
subject an item belongs to, e.g. an item grouping variable. \code{"domain"} specifies the corresponding domain,
namely ``knowledge'' or ``procedural''. This may be considered also as an item grouping variable.\\ 

Overall, we might be interested in analyses specific to distinct groups of persons (e.g. males), for example
to estimate the mean ability of males. Alternatively, we might be interested in specific groups of items (e.g. 
biology), for example to estimate the difficulty of biology items. You might be as well interested in both.\\

The long format of the ``sciences''-data is well suited for capturing both---characteristics of items and persons
as well. However, working with Conquest or TAM needs the data presented in the wide format. From a wide format data 
frame, we are only able to maintain characteristics of items or persons, but not both. The most common practice is
to provide wide format data with persons in rows and items in columns. This means that we maintain person characteristics 
but loose item characteristics. long/wide-format transformation is possible using the \code{"melt"} or \code{"cast"} 
function from the \code{"reshape2"} package. To transform the data into the wide format, we may use the following 
command:\\

<<intro02>>=
sciencesWide <- dcast(sciences, id+grade+sex+booklet+track+version~variable, value.var = "value")
@

The new data frame consists of 420 rows (according to 420 distinct persons) and 190 columns (according to 185 item 
indicators and 5 person variables). Note that we lost explicit information which item belongs to which subject and 
which domain. So it is recommended to create a ``Q matrix'' which captures information about item characteristics.
For the sake of claity we specify a Q matrix only for item subject. \\

<<intro03>>=
qMat <- sciences[!duplicated(sciences[,"variable"]),c("variable", "subject")]
qMat <- data.frame ( variable  = qMat[,"variable"], model.matrix( ~subject - 1, data = qMat) )
@
 
\section{Estimate some basic IRT models}
\label{sec:ex2}
\subsection{Unidimensional Rasch model}
\label{subsec:ex21}

The simplest IRT model is the unidimensional Rasch model. We assume only one homogeneous latent ability $\theta$ which 
accounts for the item responses. We assume that $\theta$ is normally distributed with $\theta\sim{N}(0,\sigma_{\theta}^{2})$. 
The discrimination for all items is equal and fixed to 1. \\

If we want to use Conquest, it is necessary to specify a folder with writing access and a second path of the conquest
executable file. It is recommended to use the 2007 version of Conquest 2.0. This procedure is not necessary if TAM
is used. \\

<<intro04>>=
analysisFolder <- "c:/Users/weirichs/rasch"
conquestFolder <- "N:/console_Feb2007.exe"
@

The total analysis process is partitioned into three parts: [1] specification of the model, [2] estimation of the 
model, and [3] collection of the model output. 

\begin{enumerate}
\item Specification of the model is done with the function \code{defineModel}. Several consistency checks are performed,
    the data are prepared for the corresponding software (e.g. Conquest or TAM), and the model input (if necessary)
    is written to the specified folder. 
\item Estimation of the model is done with the function \code{runModel}. This simply starts the estimator. 
\item Collection of the model output is done with the function \code{getResults}. All input is collected in a single 
    R data frame. Moreover, if desired, the output is written in the specified folder.
\end{enumerate}

We start with the model specification. The user needs to specify the data, the person identifier (column number or
column name), the item columns (character vector of item names or numeric vector which specifies the item columns).
In the current example, \code{items = -c(1:6)} means, ``every colums except columns 1 to 6 are items''. An equivalent
statement might be \code{items = 7 : 191} or \code{items = 7 : ncol(sciencesWide)}. The statement  
\code{items = unique(sciences[,"variable"])} is possible as well and often recommended to explicitly address item columns. 

<<intro04>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = -c(1:6), 
             analysis.name = "rasch", conquest.folder = conquestFolder, 
             dir = analysisFolder)
@

Up to this point, nothing is estimated. But you will find the necessary Conquest input files in the specified folder. To
start the estimation, call \code{runModel}. The object \code{modDefine} created by \code{runModel} contains information 
which are necessary for model estimation. To estimate the model, pass the \code{modDefine} object as argument for the 
subsequent function \code{runModel}.\\

<<intro05>>=
modRun    <- runModel ( modDefine )
@

To collect the output generated by Conquest into R, use \code{getResults} as the third step. \\

<<intro06>>=
results   <- getResults ( modRun )
@

\code{results} contains all model output (e.g. item parameters, person estimates, WLEs, PVs, etc.). To extract only item 
parameters from the results object, use \code{itemFromRes}. The same works for WLEs, PVs, and EAPs.\\

<<intro07>>=
items     <- itemFromRes ( results )
wle       <- wleFromRes ( results ) 
eap       <- eapFromRes ( results )
@

For plausible values, the results may displayed in the long or wide format. The wide format is defaulted.\\

<<intro08>>=
pvWide    <- pvFromRes ( results ) 
pvLong    <- pvFromRes ( results, toWideFormat = FALSE ) 
@

The same logic applies for TAM, with one exeption. It is not necessary to specify a folder for the results. 
Estimation is performed directly in R. If a result directory is specified, the results are saved in this
directory additionally. Note that the object returned by \code{runModel} is of class \code{tam.mml}. Hence, 
all \code{TAM}-functions (like \code{tam.wle} can be applied to this object. The code for the same analysis 
in TAM is the following: \\

<<intro09>>=
modDefTam <- defineModel(dat = sciencesWide, id = "id", items = -c(1:6), software = "tam")
modRunTam <- runModel ( modDefTam )
class(modRunTam)
wle       <- tam.wle(modRunTam, progress = FALSE)
resultsTam<- getResults ( modRunTam )
itemsTam  <- itemFromRes ( resultsTam ) 
@

\subsection{Differential Item Functioning}
\label{subsec:ex22}

Estimation of DIF simply needs to add one argument into the present function call---we need to specify the
person grouping variable for which DIF should be estimated. In our example, this is the ``sex'' variable.
Using the \code{DIF.var} argument, we may specify the column or the name of the DIF variable.\\

<<intro10>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = -c(1:6), 
             analysis.name = "DIF", DIF.var = "sex", conquest.folder = conquestFolder, 
             dir = analysisFolder)
@

Several messages are printed on the console which might encourage us to recode the data: First wes see 
that the ``sex'' variable war transformed to a numeric variable with values 1, 2. This is necessary as 
Conquest does not allow character values like ``male'' or ``female'' in explicit variables. In principle, 
the numeric values of the DIF variable are arbitrary, but the most common practice is to choose one reference 
group with value 0, and a focus group with value 1. This leads to results which are easily interpretable. 
So lets recode the data by adding a new numeric ``sex'' variable to the data frame. \\

<<intro11>>=
sciencesWide[,"sexNum"] <- car::recode ( var = sciencesWide[,"sex"], recodes = "'male'=0; 'female'=1", 
                           as.factor.result = FALSE)
@

As the data frame has increased by one additional column, the statement \code{items = -c(1:6)} is no longer 
appropriate, as ``every colums except columns 1 to 6 are items'' is no longer true. In general, it is a better idea
to explicitly address the items via item names. We illustry this in the following function call: \\

<<intro12>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             analysis.name = "DIF", DIF.var = "sexNum", conquest.folder = conquestFolder, 
             dir = analysisFolder)
@

Inspecting the messages printed on console, wee see that two items have a zero variance in one of 
the ``sex'' the groups. These items are automatically removed from the data prior to analysis as 
Conquest will collapse otherwise. The further processing of running the model and collecting the
results is nearly equivalent to the first example---with one exception: The decision whether an 
item has DIF often depends on two criteria, the amount of the absolut DIF value, and whether the
DIF value significantly exceeds a specific boundary value. For example, the ETS criterion 
defines DIF if the absolut DIF value exceeds 0.64 \emph{and} if the DIF is---on a 90
percent significance level---different from 0.43. The criteria to decide whether a specific item
functions differently might be varied. This is illstrated in the following example, using the ETS 
citerion:\\

<<intro13>>=
modRun    <- runModel(modDefine)
results   <- getResults(modRun, abs.dif.bound = 0.64, sig.dif.bound = 0.43, p.value = 0.9)
items     <- itemFromRes(results)
@

The column \code{"difIndex"} in the \code{items} table is 0 for items which do not fulfill the 
specified DIF criterion, and 1 for items which are considered to have DIF.\\

\subsection{Latent Regression Model}
\label{subsec:ex23}

In the estimation of national trends, IRT models often include latent regression and anchored 
item parameters---for example in the plausible values imputation. Both is illustrated in the 
following. We include the class level and sex as regression variables to account for possible 
ability differences between class level 9 and 10 as well as males and females. To yield better 
interpretable results, class level is recoded, where level 9 is the reference group, and level 
10 is the focus group. Hence, we recode 9 to 0, and 10 to 1. Moreover, we use the parameters 
estimated previously as anchor parameters for the items. Including anchor parameters simply 
needs to provide a data frame with two columns (first column: item identifier, second column: 
parameter value) which is passed to \code{defineModel} via the \code{anchor} argument. Items
occurring only in the \code{anchor} list but not in the data will be ignored. Items occurring 
only in the data but not in the \code{anchor} list will be estimated freely. \\

<<intro13>>=
sciencesWide[,"gradeRecode"] <- car::recode(var = sciencesWide[,"grade"], recodes = "9=0; 10=1", 
                                as.factor.result = FALSE)
anchorItems <- items[,c("item", "est")]
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             analysis.name = "latentRegression", HG.var = c("sexNum", "gradeRecode"), 
             anchor = anchorItems, conquest.folder = conquestFolder, dir = analysisFolder)
modRun    <- runModel(modDefine)
@

\subsection{Multidimensional Models}
\label{subsec:ex24}

Specifying a model with multiple latent traits which are allowed to correlate needs
to specify which item belongs to which latent dimension or construct. This is easily 
done with the Q matrix which was created previously. The Q matrix has to be specified 
in a seperat argument \code{qMatrix}. Note that multidimensional models may require 
considerable computational effort---so sometimes it is preferable to use 
\code{method = "montecarlo"} instead of gaussian quadrature integration (which is
the default method). Only for the purpose of illustration, we use Monte Carlo 
Integration with only 4000 nodes.\\

<<intro14>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             qMatrix = qMat, method = "montecarlo", nodes = 4000, analysis.name = "threedim", 
             conquest.folder = conquestFolder, dir = analysisFolder)
modRun    <- runModel(modDefine)
@

\subsection{2PL Models}
\label{subsec:ex25}

Conquest does not support the estimation of 2pl/3pl models---hence we will refer to the 
TAM package for the following examples. More detail may be found in the documentation 
for this package. First we define a simple 2pl model, i.e. for each item a difficulty
and a discrimination parameter is estimated. Extracting the item parameters from the 
results object via \code{itemFromRes} now additionally yields discrimination parameters.
Moreover, we may test whether 2pl fits the data better than 1pl.\\

<<intro14>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             irtmodel = "2PL", software = "tam")
modRun    <- runModel(modDefine)
results   <- getResults(modRun)
items     <- itemFromRes(results)
### Fit 1pl model to compare the fit
mod1pl    <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             software = "tam")
modRun1pl <- runModel(mod1pl)
anova(modRun, modRun1pl)
@

In the second example, we may test whether the discrimination of items varies according to 
some item groups. For example, differs the item discrimination between biology and chemistry 
items? For this purpose we have to create a ``slope matrix'' which defines for which groups 
of items a common slope parameter should be estimated. \\

<<intro15>>=
slopeMat  <- sciences[!duplicated(sciences[,"variable"]),c("variable", "subject")]
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             irtmodel = "2PL.groups", est.slopegroups = slopeMat, software = "tam")
modRun    <- runModel(modDefine)
tapply(modRun[["item"]][,"B.Cat1.Dim1"], substr(as.character(modRun[["item"]][,"item"]),1,3), unique)
@

\subsection{3PL Models}
\label{subsec:ex25}

3pl model estimation also is only possible in TAM. Like in 2pl models, it is possible 

\begin{itemize}
\item to estimate a common guessing parameter for all items
\item to define item groups for which a common guessing parameter should be estimated. This may be 
    useful if specific item formats suggest a common guessing mechanism---for example, for all 
    multiple choice items with four categories, the assumtion of a common guessing probability 
    is conjecturable. 
\item to estimate each item's own guessing parameter. However, this yields a high number of parameters
      to be estimated and might cause convergence trouble. 
\end{itemize}

In the first example, we omit the specification of a guessing matrix which results in the estimation
of only one unique guessing parameter for each item.\\

<<intro16>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", items = unique(sciences[,"variable"]), 
             irtmodel = "3PL", software = "tam")
modRun    <- runModel(modDefine)
@

\section{Specify and run several models in a row}
\label{sec:ex3}

In some studies, it may be necessary to specify one kind of model (for example the Rasch model) to
many groups of persons and/or items. For example, 

\begin{itemize}
\item in the IQB Laendervergleich, the multidimensional Rasch model with latent regression is applied
    to all of the 16 countries of the Federal Republic of Germany.
\item in pilot studies, the unidimensional Rasch model is applied to all of the domains (``Kompetenzbereiche''),
    including the global domain. 
\end{itemize}

It may be exhausting to repeat the syntax 16 times in nearly the same manner, so \code{eatModel} allows 
to specify some item or person groups for which the defined model is run subsequently (single core computation)
or simultaneously (multicore computation). This is done via the \code{splitModels} function.\\

In the first chapter of this vignette, the total analysis process was partitioned into the three parts of 
[1] specification, [2] estimation, and [3] result collection. The ``splitting'' of models has to be done 
previously, it is the zeroth step. The following steps nearly remain unchanged. In the first example, 
let's assume we want to specify a unidimensional Rasch model for each of the subject domains (biology, 
chemistry, physics) separately. As domains are a characteristic of items, this results in a separation 
of item groups. Hence, we need the Q matrix defined in the introduction of this vignette. We have to 
tell \code{splitModels} that the model split is due to \emph{item groups}. \\

<<intro17>>=
modSplit  <- splitModels(qMatrix = qMat, split = "qMatrix", nCores = 1)
@

\code{nCores} defines the number of logical processors used for estimation. The specification 
of \code{nCores = 1} results in single core computation. If \code{nCores} is not specified, 
the function by default uses all available cores for estimation. \code{splitModels} creates
an object which now is given to \code{defineModel} as additional argument. \\

<<intro18>>=
modDefine <- defineModel(dat = sciencesWide, id = "id", splittedModels = modSplit, 
             dir = analysisFolder, conquest.folder = conquestFolder)
modRun    <- runModel(modDefine)
results   <- getResults(modRun)
@

As you might have seen, \code{defineModel} no longer needs the \code{items} argument which was 
obligatory before. The reason is that the choice of items varies between the three models defined
in \code{splitModels}. So the \code{modSplit} object includes information about the choice of 
items used for each of the three models. \\

It is possible to modify the object \code{modSplit} after it was created by \code{splitModels}. Let's 
assume we want to change the seed and the number of nodes between biology, chemistry and physics. 
\code{modSplit} is a list with three elements, the first element is a data.frame named ``models'', 
the second is a list named ``models.splitted'', and the third is a scalar with the number of intended 
cores. Only the first data.frame is intended for further modification:\\

<<intro18>>=
sapply(modSplit, class)
modSplit[["models"]]
modSplit[["models"]][,"seed"] <- c(150, 225, 665)
modSplit[["models"]][,"nodes"]<- c(8000, 12000, 20000)
modDefine <- defineModel(dat = sciencesWide, id = "id", splittedModels = modSplit, 
             method = "montecarlo", dir = analysisFolder, conquest.folder = conquestFolder)
@

Changing the seed and nodes simply needs to add new columns to the \code{modSplit[["models"]]} 
data frame. Note that the column names must match one of the argument names of \code{defineModel}. 
Hence, an additional columns named \code{Seed} would be ignored.\\

Model split also works for person groups. Assume that we want to estimate the model for both 
grades (9 and 10) as well as for both sex groups (males and females) separately. The model 
split now is due to \emph{person groups}. Considering only the subgroups would result in 
$2\times 2=4$ models. However, if we consider also the whole group and the superior subgroups,
9 models are defined: 4 subgroups plus all girls in grade 9+10, all boys in grade 9+10, 
boys+girls in grade 9, and boys+girls in grade 10, and boys+girls in grade 9+10. For more
details, see the help file of \code{splitModels}, especially the \code{person.split.depth}
argument. \\

<<intro19>>=
modSplit  <- eatModel::splitModels(person.groups = sciencesWide[,c("id", "sex", "grade")], 
             all.persons = TRUE, split = "person.groups", nCores = 1)
modDefine <- defineModel(dat = sciencesWide, items = unique(sciences[,"variable"]), 
             id = "id", splittedModels = modSplit, software = "tam")
@


%%\section{last chapter}
%%\label{sec:last}

%%The final chapter is designated to provided an example which is closely related to the common practice of
%%large-scale assessments, for example in the ``Laendervergleich'' studies processed at the
%%Institute for Educational Quality Improvement (IQB). We use artificial data from Weirich et al. (in press).
%%First, we have to load the data and two necessary libraries, \code{mice} and \code{eatModel}.\\

%%<<loadLib>>=
%%library(mice)
%%library(eatModel)
%%data(testdata)
%%str(testdata)
%%@

%%Most variables in the dataset will seen familiar to you, with two exeptions: First the \code{sex} and
%%\code{hisei} variables now have a substantial amount of missing data. Second the data set does not
%%contain (imputed) values for the corresponding scale (``reading ability'') but only the responses
%%to the items (column \code{"resp"}). Hence, these data might be directly result from the questionnaires
%%in a large-scale assessment. We now would have to impute the missing data on the demographic variables
%%which we will use afterwards in the conditioning model to obtain the plausible values. Typically, this
%%is done within four steps:

%%\begin{enumerate}
%%\item The first step is calibration of the items, where we will use a simple unidimensional Rasch model.
%% We want to estimate item parameters on the one hand and a proxy for $\theta$ which is inherently unobserved
%% in latent measurement models but nevertheless necessary in the imputation model.
%%\item The second step is imputation of \code{sex} and \code{hisei}. According to a MAR assumption, we
%% suppose that the probability of a missing response on \code{sex} and \code{hisei} might depend on $\theta$.
%% Hence, $\theta$ should be included in the imputation model. We will generate 5 imputed data sets.
%%\item The third step is drawing plausible values. Having generated several complete data sets, we specify
%% the conditioning model on each data set and draw plausible values in each case.
%%\item The last step is to collect the plethore of plausible values and compute the quantities of interest.
%%\end{enumerate}

%%In the first step, we reshape the data into the wide format and call \code{defineModel} from the \code{eatModel}
%%package. For the sake of speed, we will use \code{TAM} instead of Conquest for estimation.\\

%%<<calibrate>>=
%%datW <- reshape2::dcast(testdata, idstud+country+sex+hisei+wgtSTUD+JKZone+JKrep~variable,
%%        value.var = "resp")
%%defM <- defineModel(dat = datW, items = unique(testdata[,"variable"]), id="idstud",
%%        software="tam")
%%runM <- runModel(defM)
%%@

%%In the second step, we use WLEs scores obtained from the calibration model as an ``auxiliary variable''
%%in the imputation of \code{sex} and \code{hisei}.

%%<<imputation>>=
%%wle  <- tam.wle(runM)
%%datI <- merge(wle[,c("pid", "theta")], datW[,c("idstud", "sex", "hisei")],
%%        by.x = "pid", by.y = "idstud", all=TRUE)
%%### data set for imputation
%%dat  <- datI[,-1]
%%toImp<- lapply(dat, FUN = function ( d ) { length(which(is.na(d))) })
%%toImp<- names ( which(toImp > 0) )
%%mdp  <- md.pairs( dat )
%%ini  <- mice(dat,  max=0, defaultMethod=c("norm", "logreg", "polyreg"), print = FALSE)
%%imputMethod <- ini$meth
%%imp.pg      <- mice(dat, meth = imputMethod, m = 5, max=1, seed=10000, printFlag = FALSE)
%%imp.i.pg    <- imp.pg
%%for (iii in 1:10){
%%     imp.i.pg <- mice.mids(imp.i.pg, maxit=1, printFlag = FALSE)}
%%dat.imp <- complete(imp.i.pg,action="long")
%%dat.imp <- do.call("rbind", by(data = dat.imp, INDICES = dat.imp[,".imp"], FUN = function ( x ) {
%%           return ( data.frame ( datI[,"pid", drop=FALSE], x , stringsAsFactors = FALSE))}))
%%colnames(dat.imp) <- gsub(".imp", "nest", colnames(dat.imp))
%%@

%%We now have five complete data sets. In the third step, the conditioning model is applied on
%%each data set. This is realized using a ``by''-loop. The item parameters from the
%%calibration model now are used as anchor parameters. The conditioning model is estimated
%%in each country separately. \\

%%<<conditioning>>=
%%datC <- merge(dat.imp, datW[,c("idstud", "country", "wgtSTUD","JKZone", "JKrep")],
%%        by.x = "pid", by.y ="idstud", all=TRUE)
%%datC <- by(data = dat.imp, INDICES = dat.imp[,c("nest", "country")], FUN = function ( sub.dat ) {
%%        browser()})
%%@

%% \bibliography{eatrep}

\end{document}
